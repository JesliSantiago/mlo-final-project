{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pytorch\n",
    "# !pip3 install torch torchvision torchaudio --quiet\n",
    "# # install pytorch lighting\n",
    "# !pip install pytorch-lightning --quiet\n",
    "# !pip install --upgrade pytorch-lightning --quiet\n",
    "# # install weights and biases\n",
    "# !pip install wandb --quiet\n",
    "# !pip install --upgrade wandb --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import wandb\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjjdsantiago3\u001b[0m (\u001b[33mmsds_mlops2023_lt2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to weights and biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230909_184016-8r1qfvaj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/8r1qfvaj' target=\"_blank\">devout-donkey-7</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/8r1qfvaj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/8r1qfvaj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/8r1qfvaj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2b16e3b4310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"mlo-final-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"Poems\",\n",
    "    \"epochs\": epochs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = poem_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 1.3785 - acc: 0.2676 - val_loss: 1.3592 - val_acc: 0.2798\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.3597 - acc: 0.3587 - val_loss: 1.3428 - val_acc: 0.3036\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.3456 - acc: 0.4230 - val_loss: 1.3353 - val_acc: 0.3095\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.3334 - acc: 0.4723 - val_loss: 1.3274 - val_acc: 0.3155\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 1.3175 - acc: 0.4858 - val_loss: 1.3212 - val_acc: 0.3452\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.2986 - acc: 0.5022 - val_loss: 1.3124 - val_acc: 0.3512\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.2785 - acc: 0.5262 - val_loss: 1.3035 - val_acc: 0.3512\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.2553 - acc: 0.5426 - val_loss: 1.2950 - val_acc: 0.3690\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.2277 - acc: 0.5396 - val_loss: 1.2857 - val_acc: 0.3988\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.1960 - acc: 0.5710 - val_loss: 1.2783 - val_acc: 0.3869\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 1.1650 - acc: 0.5620 - val_loss: 1.2694 - val_acc: 0.3988\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.1327 - acc: 0.6143 - val_loss: 1.2651 - val_acc: 0.4048\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.1002 - acc: 0.6188 - val_loss: 1.2583 - val_acc: 0.3988\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.0674 - acc: 0.6532 - val_loss: 1.2555 - val_acc: 0.4048\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.0334 - acc: 0.6667 - val_loss: 1.2503 - val_acc: 0.4226\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.0002 - acc: 0.6667 - val_loss: 1.2496 - val_acc: 0.3869\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.9691 - acc: 0.6831 - val_loss: 1.2490 - val_acc: 0.4048\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.9338 - acc: 0.7115 - val_loss: 1.2534 - val_acc: 0.4107\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.9084 - acc: 0.7160 - val_loss: 1.2461 - val_acc: 0.3988\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.8765 - acc: 0.7160 - val_loss: 1.2449 - val_acc: 0.4464\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.8545 - acc: 0.7205 - val_loss: 1.2555 - val_acc: 0.4048\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.8299 - acc: 0.7190 - val_loss: 1.2511 - val_acc: 0.4405\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.8016 - acc: 0.7444 - val_loss: 1.2601 - val_acc: 0.3929\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.7788 - acc: 0.7459 - val_loss: 1.2714 - val_acc: 0.4048\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.7576 - acc: 0.7623 - val_loss: 1.2650 - val_acc: 0.4345\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.7408 - acc: 0.7668 - val_loss: 1.2704 - val_acc: 0.4583\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7126 - acc: 0.7683 - val_loss: 1.2817 - val_acc: 0.4048\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6963 - acc: 0.7907 - val_loss: 1.2865 - val_acc: 0.4464\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6753 - acc: 0.7862 - val_loss: 1.2955 - val_acc: 0.4405\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6657 - acc: 0.7952 - val_loss: 1.3043 - val_acc: 0.4583\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6445 - acc: 0.7922 - val_loss: 1.3129 - val_acc: 0.4524\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6251 - acc: 0.8146 - val_loss: 1.3217 - val_acc: 0.4643\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6094 - acc: 0.8102 - val_loss: 1.3372 - val_acc: 0.4405\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5953 - acc: 0.8042 - val_loss: 1.3433 - val_acc: 0.4405\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5831 - acc: 0.8161 - val_loss: 1.3612 - val_acc: 0.4286\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5742 - acc: 0.8132 - val_loss: 1.3758 - val_acc: 0.4405\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5548 - acc: 0.8236 - val_loss: 1.3782 - val_acc: 0.4345\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5386 - acc: 0.8386 - val_loss: 1.3932 - val_acc: 0.4226\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5353 - acc: 0.8326 - val_loss: 1.4021 - val_acc: 0.4524\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5167 - acc: 0.8356 - val_loss: 1.4143 - val_acc: 0.4345\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5026 - acc: 0.8356 - val_loss: 1.4317 - val_acc: 0.4345\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4903 - acc: 0.8505 - val_loss: 1.4391 - val_acc: 0.4286\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4814 - acc: 0.8475 - val_loss: 1.4539 - val_acc: 0.4286\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4730 - acc: 0.8565 - val_loss: 1.4627 - val_acc: 0.4345\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4610 - acc: 0.8550 - val_loss: 1.4949 - val_acc: 0.4226\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4526 - acc: 0.8640 - val_loss: 1.4958 - val_acc: 0.4286\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4430 - acc: 0.8640 - val_loss: 1.5109 - val_acc: 0.4286\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4320 - acc: 0.8700 - val_loss: 1.5272 - val_acc: 0.4226\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4246 - acc: 0.8685 - val_loss: 1.5384 - val_acc: 0.4286\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4107 - acc: 0.8759 - val_loss: 1.5592 - val_acc: 0.4048\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4134 - acc: 0.8729 - val_loss: 1.5632 - val_acc: 0.4226\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3956 - acc: 0.8819 - val_loss: 1.5856 - val_acc: 0.3988\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3944 - acc: 0.8789 - val_loss: 1.5941 - val_acc: 0.4286\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3786 - acc: 0.8864 - val_loss: 1.6180 - val_acc: 0.3869\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3831 - acc: 0.8744 - val_loss: 1.6378 - val_acc: 0.4167\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3682 - acc: 0.8834 - val_loss: 1.6498 - val_acc: 0.3810\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3663 - acc: 0.8804 - val_loss: 1.6608 - val_acc: 0.3929\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3567 - acc: 0.8909 - val_loss: 1.6792 - val_acc: 0.4226\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3434 - acc: 0.9073 - val_loss: 1.6890 - val_acc: 0.4107\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3414 - acc: 0.9073 - val_loss: 1.7142 - val_acc: 0.4048\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3390 - acc: 0.8879 - val_loss: 1.7184 - val_acc: 0.3988\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3296 - acc: 0.9058 - val_loss: 1.7373 - val_acc: 0.4167\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3230 - acc: 0.9073 - val_loss: 1.7626 - val_acc: 0.3810\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3153 - acc: 0.9043 - val_loss: 1.7678 - val_acc: 0.3988\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3155 - acc: 0.9043 - val_loss: 1.7908 - val_acc: 0.3869\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3100 - acc: 0.9058 - val_loss: 1.7957 - val_acc: 0.3988\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2976 - acc: 0.9118 - val_loss: 1.8142 - val_acc: 0.3988\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2979 - acc: 0.9058 - val_loss: 1.8281 - val_acc: 0.3988\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2924 - acc: 0.9163 - val_loss: 1.8529 - val_acc: 0.3988\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2819 - acc: 0.9238 - val_loss: 1.8773 - val_acc: 0.3988\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2804 - acc: 0.9163 - val_loss: 1.8891 - val_acc: 0.4107\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2796 - acc: 0.9193 - val_loss: 1.9023 - val_acc: 0.3869\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2717 - acc: 0.9193 - val_loss: 1.9179 - val_acc: 0.4048\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2716 - acc: 0.9193 - val_loss: 1.9328 - val_acc: 0.3988\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2679 - acc: 0.9103 - val_loss: 1.9617 - val_acc: 0.4048\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2606 - acc: 0.9133 - val_loss: 1.9693 - val_acc: 0.3988\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2505 - acc: 0.9238 - val_loss: 1.9832 - val_acc: 0.3929\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2500 - acc: 0.9268 - val_loss: 2.0002 - val_acc: 0.3869\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2491 - acc: 0.9223 - val_loss: 2.0189 - val_acc: 0.4048\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2419 - acc: 0.9283 - val_loss: 2.0373 - val_acc: 0.3869\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2390 - acc: 0.9253 - val_loss: 2.0474 - val_acc: 0.4048\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2411 - acc: 0.9238 - val_loss: 2.0709 - val_acc: 0.4107\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2334 - acc: 0.9253 - val_loss: 2.0799 - val_acc: 0.3988\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2268 - acc: 0.9238 - val_loss: 2.0937 - val_acc: 0.3988\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2286 - acc: 0.9268 - val_loss: 2.1039 - val_acc: 0.4107\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2277 - acc: 0.9283 - val_loss: 2.1400 - val_acc: 0.4107\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2229 - acc: 0.9238 - val_loss: 2.1462 - val_acc: 0.4167\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2169 - acc: 0.9372 - val_loss: 2.1636 - val_acc: 0.4167\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2112 - acc: 0.9402 - val_loss: 2.1739 - val_acc: 0.4048\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2123 - acc: 0.9342 - val_loss: 2.1888 - val_acc: 0.4167\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2068 - acc: 0.9372 - val_loss: 2.2163 - val_acc: 0.4167\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2058 - acc: 0.9387 - val_loss: 2.2235 - val_acc: 0.4107\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2017 - acc: 0.9357 - val_loss: 2.2514 - val_acc: 0.4226\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.1990 - acc: 0.9357 - val_loss: 2.2507 - val_acc: 0.4167\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2004 - acc: 0.9387 - val_loss: 2.2776 - val_acc: 0.4107\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.1955 - acc: 0.9342 - val_loss: 2.2832 - val_acc: 0.4167\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.1990 - acc: 0.9342 - val_loss: 2.3171 - val_acc: 0.4167\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.1939 - acc: 0.9327 - val_loss: 2.3090 - val_acc: 0.4167\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1922 - acc: 0.9297 - val_loss: 2.3325 - val_acc: 0.4167\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.1976 - acc: 0.9312 - val_loss: 2.3604 - val_acc: 0.4107\n"
     ]
    }
   ],
   "source": [
    "_model.load_data()\n",
    "_model.preprocess()\n",
    "_model.train(epochs=epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    wandb.log({\"val_loss\": _model.trained_model.history['val_loss'][i], \"val_acc\": _model.trained_model.history['val_acc'][i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>val_loss</td><td>‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>0.41071</td></tr><tr><td>val_loss</td><td>2.36041</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-donkey-7</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/8r1qfvaj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/8r1qfvaj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230909_184016-8r1qfvaj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Callbacks\n",
    "# early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
    "# checkpoint_callback = pl.callbacks.ModelCheckpoint()\n",
    "\n",
    "# # define model\n",
    "# model = LitModel((3, 32, 32),\n",
    "#                   dm.num_classes, \n",
    "#                   learning_rate=learning_rate,\n",
    "#                   optimizer=optimizer,\n",
    "#                   fc_layer_size=fc_layer_size\n",
    "#                  )\n",
    "\n",
    "# # Initialize a trainer\n",
    "# trainer = pl.Trainer(max_epochs=epochs,\n",
    "#                      accelerator=accelerator, \n",
    "#                      logger=wandb_logger,\n",
    "#                      callbacks=[early_stop_callback,\n",
    "#                                 ImagePredictionLogger(val_samples), # to log predictions to W&B\n",
    "#                                 checkpoint_callback],\n",
    "#                      )\n",
    "\n",
    "# # Train the model ‚ö°üöÖ‚ö°\n",
    "# trainer.fit(model, dm)\n",
    "\n",
    "# # validate\n",
    "# val_results = trainer.validate(model, dm.val_dataloader())\n",
    "\n",
    "# # Evaluate the model on the held-out test set ‚ö°‚ö°\n",
    "# # trainer.test(dataloaders=dm.test_dataloader())\n",
    "# test_results = trainer.test(model, dm.test_dataloader())\n",
    "\n",
    "# # save model\n",
    "# model_path = os.path.join(wandb.run.dir, \"model.ckpt\")\n",
    "# trainer.save_checkpoint(model_path)\n",
    "# print(f\"Saved to {model_path}\")\n",
    "\n",
    "# # Close wandb run\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
