{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeps notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import wandb\n",
    "from model import *\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sweep config\n",
    "sweep_config = {\n",
    "    'method': 'random' # random, grid, or bayes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric\n",
    "metric = {\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'   # minimize or maximize\n",
    "    }\n",
    "# add in sweep_config\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "count = 1\n",
    "architecture = 'CNN'\n",
    "dataset = 'Poems'\n",
    "# Define hyperparameter space\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'embedding_dim': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "    }\n",
    "# we can indicate the distribution for continuous variables\n",
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.0001,\n",
    "        'max': 0.1\n",
    "      }\n",
    "    })\n",
    "# we set values that we want to track but don't want to change, just indicate 1 value\n",
    "parameters_dict.update({\n",
    "    'epochs': {'value': epochs},\n",
    "    \"architecture\":{'value': architecture},\n",
    "    \"dataset\": {'value': dataset},        \n",
    "    })\n",
    "# add params in sweep_config\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'architecture': {'value': 'CNN'},\n",
      "                'dataset': {'value': 'Poems'},\n",
      "                'embedding_dim': {'values': [128, 256, 512]},\n",
      "                'epochs': {'value': 50},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.1,\n",
      "                                  'min': 0.0001},\n",
      "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjjdsantiago3\u001b[0m (\u001b[33mmsds_mlops2023_lt2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to weights and biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gs0lcwy2\n",
      "Sweep URL: https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/gs0lcwy2\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"mlo-final-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5i94635y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06392504300409665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230920_023730-5i94635y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5i94635y' target=\"_blank\">valiant-sweep-1</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/gs0lcwy2' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/gs0lcwy2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/gs0lcwy2' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/gs0lcwy2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5i94635y' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5i94635y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:52: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:54: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:55: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 18ms/step - loss: 1.4443 - acc: 0.3214 - val_loss: 1.3046 - val_acc: 0.3988\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0744 - acc: 0.5441 - val_loss: 1.4146 - val_acc: 0.4286\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8689 - acc: 0.6607 - val_loss: 2.0865 - val_acc: 0.3631\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8971 - acc: 0.6457 - val_loss: 1.9746 - val_acc: 0.4107\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7432 - acc: 0.7294 - val_loss: 2.2097 - val_acc: 0.4167\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6591 - acc: 0.7638 - val_loss: 2.3688 - val_acc: 0.3869\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5927 - acc: 0.7758 - val_loss: 2.9101 - val_acc: 0.3631\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6694 - acc: 0.7683 - val_loss: 3.0951 - val_acc: 0.3631\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6646 - acc: 0.7713 - val_loss: 3.0931 - val_acc: 0.3631\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5465 - acc: 0.8132 - val_loss: 3.2062 - val_acc: 0.3571\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5593 - acc: 0.7967 - val_loss: 3.5876 - val_acc: 0.3452\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5117 - acc: 0.8371 - val_loss: 3.8418 - val_acc: 0.3929\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5405 - acc: 0.8266 - val_loss: 3.7792 - val_acc: 0.3631\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5726 - acc: 0.8236 - val_loss: 4.6304 - val_acc: 0.3810\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4692 - acc: 0.8565 - val_loss: 4.2068 - val_acc: 0.3155\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4536 - acc: 0.8625 - val_loss: 4.3351 - val_acc: 0.3631\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3728 - acc: 0.8789 - val_loss: 4.4827 - val_acc: 0.3452\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3779 - acc: 0.8894 - val_loss: 4.5138 - val_acc: 0.3512\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4627 - acc: 0.8580 - val_loss: 4.6772 - val_acc: 0.3452\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.4411 - acc: 0.8849 - val_loss: 4.7523 - val_acc: 0.3631\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4027 - acc: 0.8819 - val_loss: 4.9666 - val_acc: 0.3452\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4817 - acc: 0.8550 - val_loss: 5.1940 - val_acc: 0.3631\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4498 - acc: 0.8714 - val_loss: 5.1598 - val_acc: 0.3512\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3849 - acc: 0.8834 - val_loss: 5.2941 - val_acc: 0.3452\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4518 - acc: 0.8819 - val_loss: 5.2099 - val_acc: 0.3512\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4393 - acc: 0.8700 - val_loss: 5.5550 - val_acc: 0.3571\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4840 - acc: 0.8924 - val_loss: 5.4212 - val_acc: 0.3333\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5925 - acc: 0.8430 - val_loss: 5.6304 - val_acc: 0.3393\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6414 - acc: 0.8401 - val_loss: 5.9376 - val_acc: 0.3690\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.4448 - acc: 0.8879 - val_loss: 5.4405 - val_acc: 0.3512\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4461 - acc: 0.8894 - val_loss: 5.8185 - val_acc: 0.3571\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3785 - acc: 0.8849 - val_loss: 5.6108 - val_acc: 0.3571\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4566 - acc: 0.8714 - val_loss: 6.2362 - val_acc: 0.3214\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4984 - acc: 0.8714 - val_loss: 6.1581 - val_acc: 0.3393\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3783 - acc: 0.8954 - val_loss: 6.3780 - val_acc: 0.3333\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6037 - acc: 0.8565 - val_loss: 6.7353 - val_acc: 0.3393\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4674 - acc: 0.8834 - val_loss: 6.8357 - val_acc: 0.3631\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4348 - acc: 0.8894 - val_loss: 7.0612 - val_acc: 0.3393\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5176 - acc: 0.8834 - val_loss: 7.3888 - val_acc: 0.3393\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5382 - acc: 0.8909 - val_loss: 6.8714 - val_acc: 0.3274\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3810 - acc: 0.8954 - val_loss: 6.8522 - val_acc: 0.3274\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4732 - acc: 0.8909 - val_loss: 6.8640 - val_acc: 0.3095\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4108 - acc: 0.8984 - val_loss: 6.9501 - val_acc: 0.3155\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4875 - acc: 0.8969 - val_loss: 6.8220 - val_acc: 0.3155\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4934 - acc: 0.8984 - val_loss: 6.8165 - val_acc: 0.3274\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.5692 - acc: 0.8580 - val_loss: 7.0787 - val_acc: 0.3274\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.3611 - acc: 0.9043 - val_loss: 7.0415 - val_acc: 0.3274\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.4992 - acc: 0.8864 - val_loss: 7.3333 - val_acc: 0.3274\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4220 - acc: 0.9058 - val_loss: 7.3493 - val_acc: 0.3512\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4098 - acc: 0.8984 - val_loss: 7.8351 - val_acc: 0.3571\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 10.9041 - acc: 0.1867\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇██▇█▇████▇▇████▇███████▇███</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▂▃▃▂▂▂▂▂▁▁▂▁▂▂▁▂▂▂▃▂▁▂▂▃▂▁▂▁▂▁▂▂▁▂▁</td></tr><tr><td>val_acc</td><td>▆█▄▇▆▄▄▄▃▆▄▅▄▃▃▃▃▄▃▃▄▂▃▄▄▄▂▃▃▄▃▃▂▁▁▁▂▂▂▄</td></tr><tr><td>val_loss</td><td>▁▁▂▂▂▃▃▃▃▄▄▅▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇█▇▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.18667</td></tr><tr><td>test_loss</td><td>10.90408</td></tr><tr><td>train_acc</td><td>0.89836</td></tr><tr><td>train_loss</td><td>0.40985</td></tr><tr><td>val_acc</td><td>0.35714</td></tr><tr><td>val_loss</td><td>7.83515</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-sweep-1</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5i94635y' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5i94635y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230920_023730-5i94635y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define hyperparam search function\n",
    "def hyperparam_search(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        # use config params\n",
    "        learning_rate = config.learning_rate\n",
    "        optimizer = config.optimizer\n",
    "        embedding_dim = config.embedding_dim\n",
    "        epochs = config.epochs\n",
    "\n",
    "        # define model\n",
    "        _model = poem_classifier_model()\n",
    "\n",
    "        _model.load_data()\n",
    "        _model.preprocess()\n",
    "        _model.train(embd_dim=embedding_dim, epochs=epochs, lr=learning_rate, optimizer=optimizer)\n",
    "\n",
    "        # print(_model.trained_model.history)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            wandb.log({\"train_loss\": _model.trained_model.history['loss'][i],\n",
    "                       \"train_acc\": _model.trained_model.history['acc'][i],\n",
    "                       \"val_loss\": _model.trained_model.history['val_loss'][i], \n",
    "                       \"val_acc\": _model.trained_model.history['val_acc'][i]})\n",
    "        \n",
    "        results = _model.test()\n",
    "        wandb.log({\"test_loss\": results[0], \"test_acc\": results[1]})\n",
    "\n",
    "wandb.agent(sweep_id, hyperparam_search, count=count) # count - num iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
