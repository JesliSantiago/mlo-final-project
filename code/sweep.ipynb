{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeps notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import wandb\n",
    "from model import *\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sweep config\n",
    "sweep_config = {\n",
    "    'method': 'random' # random, grid, or bayes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric\n",
    "metric = {\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'   # minimize or maximize\n",
    "    }\n",
    "# add in sweep_config\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "architecture = 'CNN'\n",
    "dataset = 'Poems'\n",
    "# Define hyperparameter space\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'embedding_dim': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "    }\n",
    "# we can indicate the distribution for continuous variables\n",
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.0001,\n",
    "        'max': 0.1\n",
    "      }\n",
    "    })\n",
    "# we set values that we want to track but don't want to change, just indicate 1 value\n",
    "parameters_dict.update({\n",
    "    'epochs': {'value': epochs},\n",
    "    \"architecture\":{'value': architecture},\n",
    "    \"dataset\": {'value': dataset},        \n",
    "    })\n",
    "# add params in sweep_config\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'architecture': {'value': 'CNN'},\n",
      "                'dataset': {'value': 'Poems'},\n",
      "                'embedding_dim': {'values': [128, 256, 512]},\n",
      "                'epochs': {'value': 30},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.1,\n",
      "                                  'min': 0.0001},\n",
      "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjjdsantiago3\u001b[0m (\u001b[33mmsds_mlops2023_lt2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to weights and biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: w94pa8s6\n",
      "Sweep URL: https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"mlo-final-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oia9cawn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009654640739687003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230910_184812-oia9cawn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/oia9cawn' target=\"_blank\">peach-sweep-1</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/oia9cawn' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/oia9cawn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 1s 19ms/step - loss: 1.3558 - acc: 0.3109 - val_loss: 1.3690 - val_acc: 0.2917\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.2712 - acc: 0.4469 - val_loss: 1.3217 - val_acc: 0.3810\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.1378 - acc: 0.5217 - val_loss: 1.3140 - val_acc: 0.4107\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9841 - acc: 0.6203 - val_loss: 1.4095 - val_acc: 0.3810\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8748 - acc: 0.6622 - val_loss: 1.3147 - val_acc: 0.4048\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7654 - acc: 0.7175 - val_loss: 1.4589 - val_acc: 0.4107\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6757 - acc: 0.7608 - val_loss: 1.4470 - val_acc: 0.3810\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6082 - acc: 0.7803 - val_loss: 1.5527 - val_acc: 0.3750\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5425 - acc: 0.8027 - val_loss: 1.6445 - val_acc: 0.3690\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4939 - acc: 0.8266 - val_loss: 1.7322 - val_acc: 0.3631\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4513 - acc: 0.8341 - val_loss: 1.8128 - val_acc: 0.3571\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4483 - acc: 0.8386 - val_loss: 1.8983 - val_acc: 0.3690\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4044 - acc: 0.8595 - val_loss: 2.0354 - val_acc: 0.3810\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3582 - acc: 0.8849 - val_loss: 2.1139 - val_acc: 0.3810\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.3438 - acc: 0.8909 - val_loss: 2.2453 - val_acc: 0.3512\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3178 - acc: 0.8909 - val_loss: 2.3191 - val_acc: 0.3810\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3044 - acc: 0.8894 - val_loss: 2.4077 - val_acc: 0.3810\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2829 - acc: 0.9073 - val_loss: 2.4908 - val_acc: 0.3810\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2484 - acc: 0.9193 - val_loss: 2.6574 - val_acc: 0.3452\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2661 - acc: 0.9028 - val_loss: 2.6873 - val_acc: 0.3869\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2399 - acc: 0.9148 - val_loss: 2.7840 - val_acc: 0.3512\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2348 - acc: 0.9193 - val_loss: 2.8476 - val_acc: 0.3810\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2179 - acc: 0.9238 - val_loss: 2.9666 - val_acc: 0.3750\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2172 - acc: 0.9253 - val_loss: 3.0586 - val_acc: 0.3690\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2171 - acc: 0.9238 - val_loss: 3.1237 - val_acc: 0.3631\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2070 - acc: 0.9297 - val_loss: 3.2481 - val_acc: 0.3452\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2135 - acc: 0.9297 - val_loss: 3.2957 - val_acc: 0.3512\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2100 - acc: 0.9283 - val_loss: 3.3105 - val_acc: 0.3690\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1921 - acc: 0.9342 - val_loss: 3.3413 - val_acc: 0.3690\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1865 - acc: 0.9268 - val_loss: 3.3952 - val_acc: 0.3571\n",
      "{'loss': [1.3557945489883423, 1.2712337970733643, 1.1378117799758911, 0.9841220378875732, 0.8748316764831543, 0.7654136419296265, 0.6757111549377441, 0.6081585884094238, 0.5425299406051636, 0.4939087927341461, 0.45133116841316223, 0.4482845664024353, 0.40440648794174194, 0.35823753476142883, 0.34378066658973694, 0.31775376200675964, 0.3044026494026184, 0.2828969359397888, 0.24840952455997467, 0.26611682772636414, 0.23987826704978943, 0.23478569090366364, 0.21785522997379303, 0.2172151505947113, 0.21710717678070068, 0.20698589086532593, 0.21353696286678314, 0.20999640226364136, 0.19212615489959717, 0.18654842674732208], 'acc': [0.31091180443763733, 0.4469357132911682, 0.5216741561889648, 0.6203288435935974, 0.6621823906898499, 0.7174887657165527, 0.7608370780944824, 0.7802690863609314, 0.8026905655860901, 0.8266068696975708, 0.834080696105957, 0.8385650515556335, 0.859491765499115, 0.884902834892273, 0.8908818960189819, 0.8908818960189819, 0.8893871307373047, 0.9073243737220764, 0.9192824959754944, 0.9028400778770447, 0.9147982001304626, 0.9192824959754944, 0.9237667918205261, 0.9252615571022034, 0.9237667918205261, 0.9297459125518799, 0.9297459125518799, 0.9282511472702026, 0.9342302083969116, 0.9267563819885254], 'val_loss': [1.368991732597351, 1.3217114210128784, 1.313995361328125, 1.4095147848129272, 1.3146581649780273, 1.4589375257492065, 1.4469656944274902, 1.5526806116104126, 1.6445472240447998, 1.7321561574935913, 1.8127857446670532, 1.8982923030853271, 2.0354294776916504, 2.113859176635742, 2.245288610458374, 2.3191475868225098, 2.4076504707336426, 2.4907655715942383, 2.657438278198242, 2.687342643737793, 2.7839508056640625, 2.847559690475464, 2.966583728790283, 3.0585825443267822, 3.1236696243286133, 3.248147964477539, 3.2956836223602295, 3.31050443649292, 3.3412585258483887, 3.395232677459717], 'val_acc': [0.2916666567325592, 0.380952388048172, 0.4107142984867096, 0.380952388048172, 0.4047619104385376, 0.4107142984867096, 0.380952388048172, 0.375, 0.369047611951828, 0.363095223903656, 0.3571428656578064, 0.369047611951828, 0.380952388048172, 0.380952388048172, 0.3511904776096344, 0.380952388048172, 0.380952388048172, 0.380952388048172, 0.3452380895614624, 0.386904776096344, 0.3511904776096344, 0.380952388048172, 0.375, 0.369047611951828, 0.363095223903656, 0.3452380895614624, 0.3511904776096344, 0.369047611951828, 0.369047611951828, 0.3571428656578064]}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9129 - acc: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▅▆▆▆▇▇▇▇▇▇██▇█████████████</td></tr><tr><td>train_loss</td><td>█▇▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆█▆██▆▆▆▅▅▆▆▆▅▆▆▆▄▇▅▆▆▆▅▄▅▆▆▅</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.33333</td></tr><tr><td>test_loss</td><td>2.91291</td></tr><tr><td>train_acc</td><td>0.92676</td></tr><tr><td>train_loss</td><td>0.18655</td></tr><tr><td>val_acc</td><td>0.35714</td></tr><tr><td>val_loss</td><td>3.39523</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-sweep-1</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/oia9cawn' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/oia9cawn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230910_184812-oia9cawn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e0m21s3t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02808494175379332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230910_184833-e0m21s3t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e0m21s3t' target=\"_blank\">lyric-sweep-2</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e0m21s3t' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e0m21s3t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 24ms/step - loss: 1.3856 - acc: 0.3438 - val_loss: 1.3210 - val_acc: 0.3690\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.1003 - acc: 0.5097 - val_loss: 1.2868 - val_acc: 0.4107\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.8624 - acc: 0.6607 - val_loss: 1.6990 - val_acc: 0.4048\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6974 - acc: 0.7160 - val_loss: 1.8025 - val_acc: 0.4107\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5562 - acc: 0.7833 - val_loss: 2.0100 - val_acc: 0.4107\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4759 - acc: 0.8117 - val_loss: 2.3427 - val_acc: 0.4167\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.5133 - acc: 0.8132 - val_loss: 2.9105 - val_acc: 0.4048\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5551 - acc: 0.7833 - val_loss: 2.7190 - val_acc: 0.3929\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3723 - acc: 0.8670 - val_loss: 2.9955 - val_acc: 0.3631\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.3914 - acc: 0.8535 - val_loss: 3.1538 - val_acc: 0.3750\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3670 - acc: 0.8520 - val_loss: 3.3635 - val_acc: 0.4405\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3947 - acc: 0.8505 - val_loss: 3.6014 - val_acc: 0.4107\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.3411 - acc: 0.8954 - val_loss: 3.6318 - val_acc: 0.3929\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3825 - acc: 0.8849 - val_loss: 3.8205 - val_acc: 0.4048\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3629 - acc: 0.8819 - val_loss: 3.9185 - val_acc: 0.3869\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3545 - acc: 0.8909 - val_loss: 3.9691 - val_acc: 0.4226\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3588 - acc: 0.8879 - val_loss: 4.0537 - val_acc: 0.4107\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2560 - acc: 0.9133 - val_loss: 4.3031 - val_acc: 0.4048\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3347 - acc: 0.8894 - val_loss: 4.3170 - val_acc: 0.3929\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2670 - acc: 0.9193 - val_loss: 4.5187 - val_acc: 0.3810\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2797 - acc: 0.9058 - val_loss: 4.3831 - val_acc: 0.4107\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2947 - acc: 0.9013 - val_loss: 4.7886 - val_acc: 0.3929\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3169 - acc: 0.9088 - val_loss: 4.8907 - val_acc: 0.3929\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2970 - acc: 0.9028 - val_loss: 4.7136 - val_acc: 0.4167\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.2746 - acc: 0.9163 - val_loss: 4.8910 - val_acc: 0.4167\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.2868 - acc: 0.9088 - val_loss: 4.8159 - val_acc: 0.3929\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2609 - acc: 0.9193 - val_loss: 4.8789 - val_acc: 0.3690\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.2605 - acc: 0.9268 - val_loss: 5.0692 - val_acc: 0.3690\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2633 - acc: 0.9178 - val_loss: 4.9734 - val_acc: 0.4167\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2817 - acc: 0.9103 - val_loss: 5.1644 - val_acc: 0.3929\n",
      "{'loss': [1.3855904340744019, 1.1002875566482544, 0.8623965382575989, 0.6973595023155212, 0.5562048554420471, 0.4759288728237152, 0.5132670998573303, 0.5551157593727112, 0.37232211232185364, 0.3913919925689697, 0.36700159311294556, 0.3947390913963318, 0.3411308228969574, 0.38246607780456543, 0.36294829845428467, 0.3544546365737915, 0.35878920555114746, 0.2559962570667267, 0.33474141359329224, 0.26699212193489075, 0.2796787917613983, 0.2946580648422241, 0.31691837310791016, 0.29700133204460144, 0.2745542526245117, 0.28683018684387207, 0.26090213656425476, 0.2605212926864624, 0.2632770538330078, 0.2816820740699768], 'acc': [0.3437967002391815, 0.5097159743309021, 0.6606875658035278, 0.7159940004348755, 0.7832586169242859, 0.8116592168807983, 0.8131539821624756, 0.7832586169242859, 0.8669655919075012, 0.853512704372406, 0.8520179390907288, 0.8505231738090515, 0.8953661918640137, 0.884902834892273, 0.8819133043289185, 0.8908818960189819, 0.8878923654556274, 0.9133034348487854, 0.8893871307373047, 0.9192824959754944, 0.9058296084403992, 0.9013453125953674, 0.9088191390037537, 0.9028400778770447, 0.9162929654121399, 0.9088191390037537, 0.9192824959754944, 0.9267563819885254, 0.9177877306938171, 0.9103139042854309], 'val_loss': [1.3209521770477295, 1.2868382930755615, 1.6989864110946655, 1.8024569749832153, 2.0099575519561768, 2.3427042961120605, 2.9104981422424316, 2.7189812660217285, 2.9955029487609863, 3.153792142868042, 3.363499641418457, 3.6014084815979004, 3.6317880153656006, 3.820509672164917, 3.918487071990967, 3.9691479206085205, 4.053708553314209, 4.303055763244629, 4.317018508911133, 4.518733501434326, 4.38312292098999, 4.788578033447266, 4.890697002410889, 4.713593482971191, 4.891010284423828, 4.815948009490967, 4.878905296325684, 5.069170951843262, 4.973351955413818, 5.164351463317871], 'val_acc': [0.369047611951828, 0.4107142984867096, 0.4047619104385376, 0.4107142984867096, 0.4107142984867096, 0.4166666567325592, 0.4047619104385376, 0.3928571343421936, 0.363095223903656, 0.375, 0.4404761791229248, 0.4107142984867096, 0.3928571343421936, 0.4047619104385376, 0.386904776096344, 0.4226190447807312, 0.4107142984867096, 0.4047619104385376, 0.3928571343421936, 0.380952388048172, 0.4107142984867096, 0.3928571343421936, 0.3928571343421936, 0.4166666567325592, 0.4166666567325592, 0.3928571343421936, 0.369047611951828, 0.369047611951828, 0.4166666567325592, 0.3928571343421936]}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3404 - acc: 0.2600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▇▇▆▇▇▇▇█▇▇███████████████</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▂▅▅▅▅▆▅▄▁▂█▅▄▅▃▆▅▅▄▃▅▄▄▆▆▄▂▂▆▄</td></tr><tr><td>val_loss</td><td>▁▁▂▂▂▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇█▇█▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.26</td></tr><tr><td>test_loss</td><td>5.34036</td></tr><tr><td>train_acc</td><td>0.91031</td></tr><tr><td>train_loss</td><td>0.28168</td></tr><tr><td>val_acc</td><td>0.39286</td></tr><tr><td>val_loss</td><td>5.16435</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-2</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e0m21s3t' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e0m21s3t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230910_184833-e0m21s3t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0poerlim with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07808868766322856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230910_184905-0poerlim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/0poerlim' target=\"_blank\">clean-sweep-3</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/0poerlim' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/0poerlim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 14ms/step - loss: 1.3828 - acc: 0.2556 - val_loss: 1.3662 - val_acc: 0.3333\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3765 - acc: 0.2855 - val_loss: 1.3566 - val_acc: 0.2917\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3738 - acc: 0.2900 - val_loss: 1.3507 - val_acc: 0.2917\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3724 - acc: 0.2676 - val_loss: 1.3469 - val_acc: 0.2917\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3719 - acc: 0.2825 - val_loss: 1.3452 - val_acc: 0.2917\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3713 - acc: 0.2810 - val_loss: 1.3440 - val_acc: 0.2917\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3718 - acc: 0.2840 - val_loss: 1.3429 - val_acc: 0.2917\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3698 - acc: 0.2945 - val_loss: 1.3425 - val_acc: 0.2917\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3708 - acc: 0.2780 - val_loss: 1.3419 - val_acc: 0.2857\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3700 - acc: 0.2930 - val_loss: 1.3414 - val_acc: 0.2917\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3675 - acc: 0.3019 - val_loss: 1.3414 - val_acc: 0.2976\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3697 - acc: 0.2750 - val_loss: 1.3417 - val_acc: 0.2976\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3701 - acc: 0.2900 - val_loss: 1.3410 - val_acc: 0.2976\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3689 - acc: 0.2720 - val_loss: 1.3406 - val_acc: 0.3393\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3676 - acc: 0.2825 - val_loss: 1.3401 - val_acc: 0.3333\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3683 - acc: 0.2855 - val_loss: 1.3398 - val_acc: 0.3095\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3684 - acc: 0.2885 - val_loss: 1.3396 - val_acc: 0.3452\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3690 - acc: 0.2825 - val_loss: 1.3397 - val_acc: 0.3393\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3675 - acc: 0.2900 - val_loss: 1.3395 - val_acc: 0.3452\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3672 - acc: 0.2990 - val_loss: 1.3394 - val_acc: 0.3333\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.3656 - acc: 0.3049 - val_loss: 1.3390 - val_acc: 0.3452\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3676 - acc: 0.2765 - val_loss: 1.3389 - val_acc: 0.3393\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3665 - acc: 0.2825 - val_loss: 1.3381 - val_acc: 0.3452\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3664 - acc: 0.2975 - val_loss: 1.3384 - val_acc: 0.3155\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3663 - acc: 0.2840 - val_loss: 1.3386 - val_acc: 0.3155\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3670 - acc: 0.2750 - val_loss: 1.3376 - val_acc: 0.3452\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3672 - acc: 0.2780 - val_loss: 1.3380 - val_acc: 0.3512\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3660 - acc: 0.2975 - val_loss: 1.3378 - val_acc: 0.3393\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3642 - acc: 0.2915 - val_loss: 1.3383 - val_acc: 0.3214\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3670 - acc: 0.2975 - val_loss: 1.3380 - val_acc: 0.3452\n",
      "{'loss': [1.382807970046997, 1.376538634300232, 1.3738027811050415, 1.3723978996276855, 1.3719202280044556, 1.3712555170059204, 1.3718206882476807, 1.3698400259017944, 1.3707811832427979, 1.3700497150421143, 1.3675329685211182, 1.3697049617767334, 1.370110273361206, 1.3689026832580566, 1.3676432371139526, 1.3683067560195923, 1.3683931827545166, 1.369033694267273, 1.3674838542938232, 1.3671972751617432, 1.365566611289978, 1.3676074743270874, 1.366487979888916, 1.3664337396621704, 1.3663092851638794, 1.3669580221176147, 1.3672477006912231, 1.3660056591033936, 1.3641823530197144, 1.3670399188995361], 'acc': [0.2556053698062897, 0.28550073504447937, 0.2899850606918335, 0.26756352186203003, 0.2825112044811249, 0.28101643919944763, 0.2840059697628021, 0.29446935653686523, 0.27802690863609314, 0.292974591255188, 0.30194321274757385, 0.27503737807273865, 0.2899850606918335, 0.27204781770706177, 0.2825112044811249, 0.28550073504447937, 0.28849029541015625, 0.2825112044811249, 0.2899850606918335, 0.298953652381897, 0.30493274331092834, 0.2765321433544159, 0.2825112044811249, 0.2974588871002197, 0.2840059697628021, 0.27503737807273865, 0.27802690863609314, 0.2974588871002197, 0.29147982597351074, 0.2974588871002197], 'val_loss': [1.3661891222000122, 1.356612205505371, 1.350700855255127, 1.3469020128250122, 1.3452448844909668, 1.3440191745758057, 1.3428850173950195, 1.342517375946045, 1.3418768644332886, 1.341444969177246, 1.3413645029067993, 1.3416907787322998, 1.3410316705703735, 1.3405606746673584, 1.3400959968566895, 1.339762568473816, 1.3396198749542236, 1.3396942615509033, 1.3395299911499023, 1.3394434452056885, 1.3389761447906494, 1.3388742208480835, 1.3380693197250366, 1.338427186012268, 1.3385884761810303, 1.3376163244247437, 1.3379509449005127, 1.3378130197525024, 1.3382655382156372, 1.3379873037338257], 'val_acc': [0.3333333432674408, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2857142984867096, 0.2916666567325592, 0.2976190447807312, 0.2976190447807312, 0.2976190447807312, 0.3392857015132904, 0.3333333432674408, 0.3095238208770752, 0.3452380895614624, 0.3392857015132904, 0.3452380895614624, 0.3333333432674408, 0.3452380895614624, 0.3392857015132904, 0.3452380895614624, 0.3154761791229248, 0.3154761791229248, 0.3452380895614624, 0.3511904776096344, 0.3392857015132904, 0.3214285671710968, 0.3452380895614624]}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5699 - acc: 0.1133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▅▆▃▅▅▅▇▄▆█▄▆▃▅▅▆▅▆▇█▄▅▇▅▄▄▇▆▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▄▄▃▃▃▂▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂</td></tr><tr><td>val_acc</td><td>▆▂▂▂▂▂▂▂▁▂▂▂▂▇▆▄▇▇▇▆▇▇▇▄▄▇█▇▅▇</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.11333</td></tr><tr><td>test_loss</td><td>1.56987</td></tr><tr><td>train_acc</td><td>0.29746</td></tr><tr><td>train_loss</td><td>1.36704</td></tr><tr><td>val_acc</td><td>0.34524</td></tr><tr><td>val_loss</td><td>1.33799</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-sweep-3</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/0poerlim' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/0poerlim</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230910_184905-0poerlim\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 01u4o2jb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06779997706885234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230910_184926-01u4o2jb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/01u4o2jb' target=\"_blank\">firm-sweep-4</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/01u4o2jb' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/01u4o2jb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 12ms/step - loss: 1.3806 - acc: 0.2720 - val_loss: 1.3722 - val_acc: 0.3214\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3726 - acc: 0.2825 - val_loss: 1.3661 - val_acc: 0.3155\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3698 - acc: 0.2885 - val_loss: 1.3633 - val_acc: 0.3155\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3681 - acc: 0.2825 - val_loss: 1.3626 - val_acc: 0.3036\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3674 - acc: 0.2765 - val_loss: 1.3616 - val_acc: 0.3036\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3670 - acc: 0.2735 - val_loss: 1.3613 - val_acc: 0.2560\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3666 - acc: 0.2810 - val_loss: 1.3606 - val_acc: 0.3095\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3666 - acc: 0.2631 - val_loss: 1.3606 - val_acc: 0.2976\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3646 - acc: 0.3019 - val_loss: 1.3609 - val_acc: 0.3036\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3647 - acc: 0.3124 - val_loss: 1.3608 - val_acc: 0.2798\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3644 - acc: 0.3214 - val_loss: 1.3606 - val_acc: 0.2857\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3639 - acc: 0.2945 - val_loss: 1.3604 - val_acc: 0.3036\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3646 - acc: 0.3079 - val_loss: 1.3602 - val_acc: 0.2976\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3648 - acc: 0.3049 - val_loss: 1.3602 - val_acc: 0.3095\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3629 - acc: 0.3079 - val_loss: 1.3598 - val_acc: 0.3155\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3635 - acc: 0.3019 - val_loss: 1.3595 - val_acc: 0.2976\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3628 - acc: 0.2885 - val_loss: 1.3601 - val_acc: 0.2917\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3612 - acc: 0.3019 - val_loss: 1.3600 - val_acc: 0.3214\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3629 - acc: 0.3019 - val_loss: 1.3602 - val_acc: 0.3036\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3619 - acc: 0.2855 - val_loss: 1.3600 - val_acc: 0.3095\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3626 - acc: 0.2810 - val_loss: 1.3607 - val_acc: 0.2917\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3616 - acc: 0.3034 - val_loss: 1.3608 - val_acc: 0.2857\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3611 - acc: 0.2945 - val_loss: 1.3606 - val_acc: 0.2976\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3613 - acc: 0.3049 - val_loss: 1.3604 - val_acc: 0.3036\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3608 - acc: 0.2945 - val_loss: 1.3605 - val_acc: 0.2976\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3608 - acc: 0.3019 - val_loss: 1.3602 - val_acc: 0.3095\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3609 - acc: 0.3004 - val_loss: 1.3603 - val_acc: 0.2976\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3581 - acc: 0.3318 - val_loss: 1.3606 - val_acc: 0.2976\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3595 - acc: 0.3184 - val_loss: 1.3601 - val_acc: 0.3214\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3610 - acc: 0.2945 - val_loss: 1.3602 - val_acc: 0.3095\n",
      "{'loss': [1.3806072473526, 1.3725793361663818, 1.3697501420974731, 1.3681180477142334, 1.3673616647720337, 1.367000937461853, 1.3665555715560913, 1.3666454553604126, 1.364594578742981, 1.3647093772888184, 1.3643940687179565, 1.363925814628601, 1.3645553588867188, 1.3647733926773071, 1.3628594875335693, 1.3634876012802124, 1.362831950187683, 1.3611506223678589, 1.3629497289657593, 1.3619410991668701, 1.3626422882080078, 1.3616015911102295, 1.361124038696289, 1.3612526655197144, 1.360807180404663, 1.3607882261276245, 1.3608750104904175, 1.358074426651001, 1.3594741821289062, 1.361010193824768], 'acc': [0.27204781770706177, 0.2825112044811249, 0.28849029541015625, 0.2825112044811249, 0.2765321433544159, 0.2735426127910614, 0.28101643919944763, 0.2630792260169983, 0.30194321274757385, 0.3124065697193146, 0.32137519121170044, 0.29446935653686523, 0.30792227387428284, 0.30493274331092834, 0.30792227387428284, 0.30194321274757385, 0.28849029541015625, 0.30194321274757385, 0.30194321274757385, 0.28550073504447937, 0.28101643919944763, 0.3034379780292511, 0.29446935653686523, 0.30493274331092834, 0.29446935653686523, 0.30194321274757385, 0.3004484176635742, 0.33183857798576355, 0.31838566064834595, 0.29446935653686523], 'val_loss': [1.372206211090088, 1.3661267757415771, 1.3633239269256592, 1.362554907798767, 1.3615601062774658, 1.361313819885254, 1.3606085777282715, 1.3605748414993286, 1.3608719110488892, 1.3608355522155762, 1.360609531402588, 1.3604100942611694, 1.3602277040481567, 1.360213279724121, 1.3598463535308838, 1.3595088720321655, 1.3601161241531372, 1.3599883317947388, 1.360234260559082, 1.360047459602356, 1.3606714010238647, 1.3608181476593018, 1.3605958223342896, 1.3604000806808472, 1.3604519367218018, 1.3601552248001099, 1.3603025674819946, 1.36063551902771, 1.3601168394088745, 1.3601670265197754], 'val_acc': [0.3214285671710968, 0.3154761791229248, 0.3154761791229248, 0.3035714328289032, 0.3035714328289032, 0.255952388048172, 0.3095238208770752, 0.2976190447807312, 0.3035714328289032, 0.2797619104385376, 0.2857142984867096, 0.3035714328289032, 0.2976190447807312, 0.3095238208770752, 0.3154761791229248, 0.2976190447807312, 0.2916666567325592, 0.3214285671710968, 0.3035714328289032, 0.3095238208770752, 0.2916666567325592, 0.2857142984867096, 0.2976190447807312, 0.3035714328289032, 0.2976190447807312, 0.3095238208770752, 0.2976190447807312, 0.2976190447807312, 0.3214285671710968, 0.3095238208770752]}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6089 - acc: 0.1400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▂▃▄▃▂▂▃▁▅▆▇▄▆▅▆▅▄▅▅▃▃▅▄▅▄▅▅█▇▄</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▁▁▂</td></tr><tr><td>val_acc</td><td>█▇▇▆▆▁▇▅▆▄▄▆▅▇▇▅▅█▆▇▅▄▅▆▅▇▅▅█▇</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▁▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.14</td></tr><tr><td>test_loss</td><td>1.60886</td></tr><tr><td>train_acc</td><td>0.29447</td></tr><tr><td>train_loss</td><td>1.36101</td></tr><tr><td>val_acc</td><td>0.30952</td></tr><tr><td>val_loss</td><td>1.36017</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-sweep-4</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/01u4o2jb' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/01u4o2jb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230910_184926-01u4o2jb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e1tet2j1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02439222145389936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230910_184942-e1tet2j1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e1tet2j1' target=\"_blank\">smart-sweep-5</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/w94pa8s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e1tet2j1' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/e1tet2j1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 28ms/step - loss: 1.3669 - acc: 0.3333 - val_loss: 1.4990 - val_acc: 0.3036\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.1602 - acc: 0.4828 - val_loss: 1.3042 - val_acc: 0.3571\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.8827 - acc: 0.6607 - val_loss: 1.5049 - val_acc: 0.3750\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7489 - acc: 0.7115 - val_loss: 1.6263 - val_acc: 0.3452\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6307 - acc: 0.7638 - val_loss: 1.8153 - val_acc: 0.3810\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5764 - acc: 0.7877 - val_loss: 2.0118 - val_acc: 0.3452\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5237 - acc: 0.8087 - val_loss: 2.0693 - val_acc: 0.3452\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4586 - acc: 0.8311 - val_loss: 2.2774 - val_acc: 0.3393\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4214 - acc: 0.8535 - val_loss: 2.4483 - val_acc: 0.3333\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3808 - acc: 0.8610 - val_loss: 2.6437 - val_acc: 0.3393\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4190 - acc: 0.8535 - val_loss: 2.8871 - val_acc: 0.3393\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3378 - acc: 0.8909 - val_loss: 2.8824 - val_acc: 0.3393\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3350 - acc: 0.8819 - val_loss: 3.2478 - val_acc: 0.3512\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2691 - acc: 0.8969 - val_loss: 3.3693 - val_acc: 0.3274\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2983 - acc: 0.8924 - val_loss: 3.4146 - val_acc: 0.3571\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4001 - acc: 0.8610 - val_loss: 3.9006 - val_acc: 0.3155\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2668 - acc: 0.9193 - val_loss: 3.8243 - val_acc: 0.3452\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2755 - acc: 0.9073 - val_loss: 3.8527 - val_acc: 0.3155\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2343 - acc: 0.9163 - val_loss: 4.1065 - val_acc: 0.3393\n",
      "Epoch 20/30\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.2419 - acc: 0.9199"
     ]
    }
   ],
   "source": [
    "# define hyperparam search function\n",
    "def hyperparam_search(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        # use config params\n",
    "        learning_rate = config.learning_rate\n",
    "        optimizer = config.optimizer\n",
    "        embedding_dim = config.embedding_dim\n",
    "        epochs = config.epochs\n",
    "\n",
    "        # define model\n",
    "        _model = poem_classifier_model()\n",
    "\n",
    "        _model.load_data()\n",
    "        _model.preprocess()\n",
    "        _model.train(embd_dim=embedding_dim, epochs=epochs, lr=learning_rate, optimizer=optimizer)\n",
    "\n",
    "        # print(_model.trained_model.history)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            wandb.log({\"train_loss\": _model.trained_model.history['loss'][i],\n",
    "                       \"train_acc\": _model.trained_model.history['acc'][i],\n",
    "                       \"val_loss\": _model.trained_model.history['val_loss'][i], \n",
    "                       \"val_acc\": _model.trained_model.history['val_acc'][i]})\n",
    "        \n",
    "        results = _model.test()\n",
    "        wandb.log({\"test_loss\": results[0], \"test_acc\": results[1]})\n",
    "\n",
    "wandb.agent(sweep_id, hyperparam_search, count=10) # count - num iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
