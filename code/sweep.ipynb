{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeps notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import wandb\n",
    "from model import *\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sweep config\n",
    "sweep_config = {\n",
    "    'method': 'random' # random, grid, or bayes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric\n",
    "metric = {\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'   # minimize or maximize\n",
    "    }\n",
    "# add in sweep_config\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "architecture = 'CNN'\n",
    "dataset = 'Poems'\n",
    "# Define hyperparameter space\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'embedding_dim': {\n",
    "        'values': [256, 512]\n",
    "        },\n",
    "    }\n",
    "# we can indicate the distribution for continuous variables\n",
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.0001,\n",
    "        'max': 0.1\n",
    "      }\n",
    "    })\n",
    "# we set values that we want to track but don't want to change, just indicate 1 value\n",
    "parameters_dict.update({\n",
    "    'epochs': {'value': epochs},\n",
    "    \"architecture\":{'value': architecture},\n",
    "    \"dataset\": {'value': dataset},        \n",
    "    })\n",
    "# add params in sweep_config\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'architecture': {'value': 'CNN'},\n",
      "                'dataset': {'value': 'Poems'},\n",
      "                'embedding_dim': {'values': [256, 512]},\n",
      "                'epochs': {'value': 100},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.1,\n",
      "                                  'min': 0.0001},\n",
      "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjjdsantiago3\u001b[0m (\u001b[33mmsds_mlops2023_lt2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to weights and biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 77qlslpj\n",
      "Sweep URL: https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"mlo-final-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ntyrjk87 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.043743982189250255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230909_203811-ntyrjk87</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/ntyrjk87' target=\"_blank\">soft-sweep-1</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/ntyrjk87' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/ntyrjk87</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 1.4227 - acc: 0.3169 - val_loss: 1.3486 - val_acc: 0.3452\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.1188 - acc: 0.5007 - val_loss: 1.6841 - val_acc: 0.3036\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.9486 - acc: 0.6338 - val_loss: 1.9474 - val_acc: 0.3750\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.8841 - acc: 0.6697 - val_loss: 1.8002 - val_acc: 0.3929\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7686 - acc: 0.7160 - val_loss: 2.1155 - val_acc: 0.3631\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5889 - acc: 0.7683 - val_loss: 2.1450 - val_acc: 0.3929\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4999 - acc: 0.8191 - val_loss: 2.6113 - val_acc: 0.3810\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4485 - acc: 0.8416 - val_loss: 2.9695 - val_acc: 0.3810\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4595 - acc: 0.8416 - val_loss: 3.1352 - val_acc: 0.3690\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.5472 - acc: 0.8221 - val_loss: 3.6361 - val_acc: 0.4107\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.5719 - acc: 0.8341 - val_loss: 3.6356 - val_acc: 0.3810\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.5165 - acc: 0.8341 - val_loss: 3.8888 - val_acc: 0.3571\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5620 - acc: 0.8206 - val_loss: 4.0065 - val_acc: 0.4048\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4688 - acc: 0.8580 - val_loss: 3.8811 - val_acc: 0.3988\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4437 - acc: 0.8714 - val_loss: 4.1814 - val_acc: 0.3810\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4330 - acc: 0.8744 - val_loss: 4.5390 - val_acc: 0.3571\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.4475 - acc: 0.8610 - val_loss: 4.5010 - val_acc: 0.3393\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4947 - acc: 0.8475 - val_loss: 4.7257 - val_acc: 0.3810\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4882 - acc: 0.8804 - val_loss: 4.8470 - val_acc: 0.3690\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3998 - acc: 0.9013 - val_loss: 4.5049 - val_acc: 0.3929\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3674 - acc: 0.9043 - val_loss: 4.7133 - val_acc: 0.3988\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4670 - acc: 0.8879 - val_loss: 4.9361 - val_acc: 0.3690\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3900 - acc: 0.9088 - val_loss: 4.7088 - val_acc: 0.3631\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4100 - acc: 0.8849 - val_loss: 4.5844 - val_acc: 0.4167\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5548 - acc: 0.8356 - val_loss: 5.3478 - val_acc: 0.3869\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5068 - acc: 0.8834 - val_loss: 4.9900 - val_acc: 0.3631\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4209 - acc: 0.9043 - val_loss: 5.1524 - val_acc: 0.3690\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3836 - acc: 0.8999 - val_loss: 5.1074 - val_acc: 0.3810\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4625 - acc: 0.8819 - val_loss: 5.8014 - val_acc: 0.3690\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4955 - acc: 0.8610 - val_loss: 5.5560 - val_acc: 0.4107\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4310 - acc: 0.8939 - val_loss: 5.5819 - val_acc: 0.3512\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4756 - acc: 0.8834 - val_loss: 5.6662 - val_acc: 0.4048\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5108 - acc: 0.8625 - val_loss: 5.9498 - val_acc: 0.3869\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4209 - acc: 0.8789 - val_loss: 5.9752 - val_acc: 0.3929\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4498 - acc: 0.9193 - val_loss: 5.8285 - val_acc: 0.3810\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4245 - acc: 0.9028 - val_loss: 5.8864 - val_acc: 0.3810\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4405 - acc: 0.9088 - val_loss: 6.0171 - val_acc: 0.3512\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5098 - acc: 0.8864 - val_loss: 5.9535 - val_acc: 0.3571\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3906 - acc: 0.9088 - val_loss: 5.7250 - val_acc: 0.3988\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5664 - acc: 0.8610 - val_loss: 6.2573 - val_acc: 0.3631\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4559 - acc: 0.8909 - val_loss: 6.1567 - val_acc: 0.3631\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5608 - acc: 0.8894 - val_loss: 6.2885 - val_acc: 0.3750\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4964 - acc: 0.8939 - val_loss: 6.2199 - val_acc: 0.3929\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3924 - acc: 0.9013 - val_loss: 6.1475 - val_acc: 0.3810\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4686 - acc: 0.9058 - val_loss: 6.4545 - val_acc: 0.3810\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5250 - acc: 0.8894 - val_loss: 6.5802 - val_acc: 0.3750\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4135 - acc: 0.9163 - val_loss: 6.1659 - val_acc: 0.3810\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4567 - acc: 0.9088 - val_loss: 6.2603 - val_acc: 0.3988\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4916 - acc: 0.9028 - val_loss: 6.0479 - val_acc: 0.3988\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5322 - acc: 0.8789 - val_loss: 6.1978 - val_acc: 0.3988\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5045 - acc: 0.8999 - val_loss: 7.1706 - val_acc: 0.4107\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5630 - acc: 0.8789 - val_loss: 6.6411 - val_acc: 0.3810\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4908 - acc: 0.9073 - val_loss: 6.6795 - val_acc: 0.3810\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4448 - acc: 0.8969 - val_loss: 7.0330 - val_acc: 0.3810\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4118 - acc: 0.8939 - val_loss: 7.1870 - val_acc: 0.3810\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5258 - acc: 0.8954 - val_loss: 7.2371 - val_acc: 0.3810\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3956 - acc: 0.9088 - val_loss: 7.1059 - val_acc: 0.3988\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4838 - acc: 0.9043 - val_loss: 6.7484 - val_acc: 0.3929\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4947 - acc: 0.9073 - val_loss: 7.3400 - val_acc: 0.3810\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5400 - acc: 0.8729 - val_loss: 7.2810 - val_acc: 0.3393\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6282 - acc: 0.8864 - val_loss: 7.0212 - val_acc: 0.3393\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5266 - acc: 0.8894 - val_loss: 7.0149 - val_acc: 0.3929\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4864 - acc: 0.8939 - val_loss: 7.7233 - val_acc: 0.3571\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5164 - acc: 0.8864 - val_loss: 7.2913 - val_acc: 0.3571\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4636 - acc: 0.9223 - val_loss: 7.5244 - val_acc: 0.3810\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4440 - acc: 0.9028 - val_loss: 7.5345 - val_acc: 0.3929\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4802 - acc: 0.9133 - val_loss: 7.1484 - val_acc: 0.3988\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4520 - acc: 0.9058 - val_loss: 7.4780 - val_acc: 0.3631\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5807 - acc: 0.8819 - val_loss: 8.2660 - val_acc: 0.3452\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5182 - acc: 0.8999 - val_loss: 7.3917 - val_acc: 0.3750\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5371 - acc: 0.8924 - val_loss: 7.8613 - val_acc: 0.3869\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5179 - acc: 0.9073 - val_loss: 8.1365 - val_acc: 0.3631\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4143 - acc: 0.9268 - val_loss: 7.9688 - val_acc: 0.3750\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5108 - acc: 0.9028 - val_loss: 8.0763 - val_acc: 0.3631\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5443 - acc: 0.8834 - val_loss: 8.4362 - val_acc: 0.3810\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5294 - acc: 0.8924 - val_loss: 9.1920 - val_acc: 0.3452\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4843 - acc: 0.9073 - val_loss: 8.4581 - val_acc: 0.3690\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4923 - acc: 0.9193 - val_loss: 8.3908 - val_acc: 0.3810\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5159 - acc: 0.9073 - val_loss: 8.1881 - val_acc: 0.3690\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4671 - acc: 0.9103 - val_loss: 7.8320 - val_acc: 0.3810\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5416 - acc: 0.9088 - val_loss: 8.7415 - val_acc: 0.3571\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5897 - acc: 0.8984 - val_loss: 8.5554 - val_acc: 0.3869\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4770 - acc: 0.9163 - val_loss: 8.3335 - val_acc: 0.3869\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5312 - acc: 0.9148 - val_loss: 8.4806 - val_acc: 0.3690\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6064 - acc: 0.9043 - val_loss: 8.3286 - val_acc: 0.3571\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5878 - acc: 0.8879 - val_loss: 8.3530 - val_acc: 0.3512\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4517 - acc: 0.9103 - val_loss: 8.3499 - val_acc: 0.3571\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4657 - acc: 0.9238 - val_loss: 8.1927 - val_acc: 0.3750\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5445 - acc: 0.8924 - val_loss: 8.6711 - val_acc: 0.3929\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4638 - acc: 0.9193 - val_loss: 8.5081 - val_acc: 0.3810\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4587 - acc: 0.9193 - val_loss: 8.4084 - val_acc: 0.4107\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5147 - acc: 0.9013 - val_loss: 8.5704 - val_acc: 0.3512\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5613 - acc: 0.9013 - val_loss: 8.5212 - val_acc: 0.3631\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5201 - acc: 0.9088 - val_loss: 8.3095 - val_acc: 0.3631\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4910 - acc: 0.9118 - val_loss: 8.9378 - val_acc: 0.3631\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4866 - acc: 0.9223 - val_loss: 8.8978 - val_acc: 0.3869\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5601 - acc: 0.8864 - val_loss: 8.8383 - val_acc: 0.3690\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.7381 - acc: 0.8849 - val_loss: 8.9749 - val_acc: 0.3452\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5976 - acc: 0.8924 - val_loss: 8.6939 - val_acc: 0.3750\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.7882 - acc: 0.8670 - val_loss: 9.2574 - val_acc: 0.3869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>▂▅▆▅▅▇▃▅▇▃▃▅▂▆▅▇▃▅▅▇█▅▅▅▁▃▇▂▃▃▄▄▆▄▃▆▂▃▄▆</td></tr><tr><td>val_loss</td><td>▁▂▂▂▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>0.3869</td></tr><tr><td>val_loss</td><td>9.25744</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-sweep-1</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/ntyrjk87' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/ntyrjk87</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230909_203811-ntyrjk87\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r1vxtd20 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.021222360230203272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230909_203905-r1vxtd20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/r1vxtd20' target=\"_blank\">divine-sweep-2</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/r1vxtd20' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/r1vxtd20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 17ms/step - loss: 1.3763 - acc: 0.2930 - val_loss: 1.3428 - val_acc: 0.3393\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.2168 - acc: 0.4798 - val_loss: 1.2766 - val_acc: 0.3571\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9950 - acc: 0.6203 - val_loss: 1.2298 - val_acc: 0.4821\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8047 - acc: 0.6652 - val_loss: 1.3546 - val_acc: 0.4226\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6903 - acc: 0.7354 - val_loss: 1.5603 - val_acc: 0.4345\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6376 - acc: 0.7459 - val_loss: 1.7735 - val_acc: 0.3929\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5484 - acc: 0.7937 - val_loss: 1.6932 - val_acc: 0.4524\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5116 - acc: 0.8027 - val_loss: 1.8517 - val_acc: 0.3869\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4470 - acc: 0.8341 - val_loss: 2.0621 - val_acc: 0.3988\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4234 - acc: 0.8401 - val_loss: 2.2698 - val_acc: 0.4107\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.3987 - acc: 0.8505 - val_loss: 2.2996 - val_acc: 0.4107\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3688 - acc: 0.8700 - val_loss: 2.4249 - val_acc: 0.3988\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3267 - acc: 0.8909 - val_loss: 2.6336 - val_acc: 0.3929\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.3187 - acc: 0.8789 - val_loss: 2.6775 - val_acc: 0.3869\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3511 - acc: 0.8670 - val_loss: 2.8883 - val_acc: 0.3869\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3230 - acc: 0.8804 - val_loss: 2.9245 - val_acc: 0.3810\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3008 - acc: 0.8999 - val_loss: 3.0056 - val_acc: 0.3690\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2944 - acc: 0.8894 - val_loss: 3.3311 - val_acc: 0.3810\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2824 - acc: 0.8969 - val_loss: 3.2935 - val_acc: 0.3750\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2689 - acc: 0.9073 - val_loss: 3.4057 - val_acc: 0.3690\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2590 - acc: 0.9163 - val_loss: 3.4106 - val_acc: 0.3869\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2511 - acc: 0.9208 - val_loss: 3.4674 - val_acc: 0.3631\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2487 - acc: 0.8999 - val_loss: 3.5779 - val_acc: 0.3929\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2293 - acc: 0.9238 - val_loss: 3.8617 - val_acc: 0.3929\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2462 - acc: 0.9148 - val_loss: 3.7134 - val_acc: 0.3869\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2545 - acc: 0.9163 - val_loss: 3.8023 - val_acc: 0.3512\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2049 - acc: 0.9342 - val_loss: 3.9906 - val_acc: 0.3631\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3202 - acc: 0.8804 - val_loss: 4.0433 - val_acc: 0.3869\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3494 - acc: 0.8804 - val_loss: 4.0787 - val_acc: 0.3571\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2345 - acc: 0.9178 - val_loss: 4.1390 - val_acc: 0.3631\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2151 - acc: 0.9238 - val_loss: 4.0764 - val_acc: 0.3512\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2274 - acc: 0.9193 - val_loss: 4.1090 - val_acc: 0.3571\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2367 - acc: 0.9178 - val_loss: 4.2024 - val_acc: 0.3750\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2024 - acc: 0.9387 - val_loss: 4.1916 - val_acc: 0.3690\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2551 - acc: 0.9133 - val_loss: 4.3207 - val_acc: 0.3571\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2576 - acc: 0.9028 - val_loss: 4.4250 - val_acc: 0.3274\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2383 - acc: 0.9148 - val_loss: 4.3826 - val_acc: 0.3631\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2616 - acc: 0.9178 - val_loss: 4.3877 - val_acc: 0.3512\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2119 - acc: 0.9297 - val_loss: 4.4227 - val_acc: 0.3512\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2165 - acc: 0.9297 - val_loss: 4.3824 - val_acc: 0.3690\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2059 - acc: 0.9447 - val_loss: 4.4450 - val_acc: 0.3512\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2083 - acc: 0.9462 - val_loss: 4.4806 - val_acc: 0.3571\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2512 - acc: 0.9028 - val_loss: 4.4518 - val_acc: 0.3452\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2674 - acc: 0.9238 - val_loss: 4.5103 - val_acc: 0.3452\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1922 - acc: 0.9402 - val_loss: 4.5606 - val_acc: 0.3333\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1922 - acc: 0.9372 - val_loss: 4.4913 - val_acc: 0.3571\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1973 - acc: 0.9238 - val_loss: 4.4583 - val_acc: 0.3750\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1874 - acc: 0.9447 - val_loss: 4.7702 - val_acc: 0.3452\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1909 - acc: 0.9357 - val_loss: 4.6242 - val_acc: 0.3452\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1797 - acc: 0.9387 - val_loss: 4.7020 - val_acc: 0.3333\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1790 - acc: 0.9477 - val_loss: 4.6236 - val_acc: 0.3750\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1856 - acc: 0.9432 - val_loss: 4.7830 - val_acc: 0.3512\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.2453 - acc: 0.9178 - val_loss: 4.7749 - val_acc: 0.3690\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.2215 - acc: 0.9223 - val_loss: 4.6222 - val_acc: 0.3750\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.2061 - acc: 0.9268 - val_loss: 4.6059 - val_acc: 0.3810\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2200 - acc: 0.9327 - val_loss: 4.6809 - val_acc: 0.3571\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1886 - acc: 0.9327 - val_loss: 4.7099 - val_acc: 0.3333\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2133 - acc: 0.9208 - val_loss: 4.7513 - val_acc: 0.3452\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2138 - acc: 0.9342 - val_loss: 4.7105 - val_acc: 0.3631\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2082 - acc: 0.9372 - val_loss: 4.7273 - val_acc: 0.3571\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1917 - acc: 0.9402 - val_loss: 4.7264 - val_acc: 0.3452\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2135 - acc: 0.9357 - val_loss: 4.8768 - val_acc: 0.3452\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2151 - acc: 0.9312 - val_loss: 4.8180 - val_acc: 0.3393\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1744 - acc: 0.9387 - val_loss: 4.8992 - val_acc: 0.3393\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2000 - acc: 0.9432 - val_loss: 4.8689 - val_acc: 0.3571\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1879 - acc: 0.9417 - val_loss: 4.8775 - val_acc: 0.3512\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1957 - acc: 0.9357 - val_loss: 4.9925 - val_acc: 0.3512\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2094 - acc: 0.9297 - val_loss: 4.8828 - val_acc: 0.3571\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1596 - acc: 0.9462 - val_loss: 4.9538 - val_acc: 0.3571\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2059 - acc: 0.9283 - val_loss: 4.9217 - val_acc: 0.3452\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2101 - acc: 0.9297 - val_loss: 4.9377 - val_acc: 0.3512\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.1999 - acc: 0.9462 - val_loss: 4.8917 - val_acc: 0.3810\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2031 - acc: 0.9312 - val_loss: 4.9109 - val_acc: 0.3690\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1888 - acc: 0.9372 - val_loss: 5.1216 - val_acc: 0.3571\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2364 - acc: 0.9297 - val_loss: 5.1079 - val_acc: 0.3690\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1833 - acc: 0.9357 - val_loss: 5.1675 - val_acc: 0.3333\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1908 - acc: 0.9357 - val_loss: 5.1357 - val_acc: 0.3393\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2095 - acc: 0.9208 - val_loss: 5.0015 - val_acc: 0.3452\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1873 - acc: 0.9312 - val_loss: 5.0863 - val_acc: 0.3690\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1764 - acc: 0.9462 - val_loss: 5.0261 - val_acc: 0.3810\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2050 - acc: 0.9297 - val_loss: 5.0988 - val_acc: 0.3571\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2039 - acc: 0.9327 - val_loss: 5.2214 - val_acc: 0.3333\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1967 - acc: 0.9342 - val_loss: 5.0777 - val_acc: 0.3274\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1948 - acc: 0.9342 - val_loss: 5.1792 - val_acc: 0.3512\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1852 - acc: 0.9462 - val_loss: 5.0630 - val_acc: 0.3333\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2213 - acc: 0.9417 - val_loss: 5.1025 - val_acc: 0.3274\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1627 - acc: 0.9417 - val_loss: 4.9527 - val_acc: 0.3393\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1933 - acc: 0.9283 - val_loss: 4.9857 - val_acc: 0.3452\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1654 - acc: 0.9372 - val_loss: 4.9804 - val_acc: 0.3690\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1867 - acc: 0.9342 - val_loss: 5.0771 - val_acc: 0.3393\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2263 - acc: 0.9148 - val_loss: 5.2265 - val_acc: 0.3571\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2252 - acc: 0.9238 - val_loss: 5.0744 - val_acc: 0.3452\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2064 - acc: 0.9387 - val_loss: 5.0722 - val_acc: 0.3393\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1601 - acc: 0.9432 - val_loss: 5.2262 - val_acc: 0.3333\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1859 - acc: 0.9402 - val_loss: 5.1649 - val_acc: 0.3690\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1937 - acc: 0.9253 - val_loss: 5.1922 - val_acc: 0.3452\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1589 - acc: 0.9402 - val_loss: 5.1665 - val_acc: 0.3393\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1758 - acc: 0.9417 - val_loss: 5.2774 - val_acc: 0.3452\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2300 - acc: 0.9268 - val_loss: 5.1162 - val_acc: 0.3750\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1831 - acc: 0.9402 - val_loss: 5.1898 - val_acc: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>▂█▄▄▅▄▃▃▄▄▂▄▂▃▁▂▂▂▂▂▃▃▂▃▂▂▂▂▃▂▂▃▁▂▂▃▂▁▂▁</td></tr><tr><td>val_loss</td><td>▁▁▂▂▃▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>0.33333</td></tr><tr><td>val_loss</td><td>5.18981</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-sweep-2</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/r1vxtd20' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/r1vxtd20</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230909_203905-r1vxtd20\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5p54xesx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.045274784415845086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230909_203941-5p54xesx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5p54xesx' target=\"_blank\">pleasant-sweep-3</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5p54xesx' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5p54xesx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 25ms/step - loss: 1.4451 - acc: 0.2990 - val_loss: 1.3015 - val_acc: 0.3452\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.0806 - acc: 0.5575 - val_loss: 1.6244 - val_acc: 0.3571\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.9547 - acc: 0.6368 - val_loss: 1.5731 - val_acc: 0.4286\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.7335 - acc: 0.7220 - val_loss: 1.9014 - val_acc: 0.4167\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6878 - acc: 0.7489 - val_loss: 2.3894 - val_acc: 0.3929\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6881 - acc: 0.7384 - val_loss: 2.3335 - val_acc: 0.4286\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5422 - acc: 0.7907 - val_loss: 2.5074 - val_acc: 0.4345\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5632 - acc: 0.8102 - val_loss: 2.7712 - val_acc: 0.4464\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5123 - acc: 0.8326 - val_loss: 2.8934 - val_acc: 0.4345\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5663 - acc: 0.8042 - val_loss: 3.2334 - val_acc: 0.4464\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5700 - acc: 0.8027 - val_loss: 3.2984 - val_acc: 0.4345\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4161 - acc: 0.8655 - val_loss: 3.5584 - val_acc: 0.4048\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3711 - acc: 0.8924 - val_loss: 3.7737 - val_acc: 0.4107\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4349 - acc: 0.8625 - val_loss: 4.4277 - val_acc: 0.3988\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5204 - acc: 0.8356 - val_loss: 4.4923 - val_acc: 0.4226\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4714 - acc: 0.8580 - val_loss: 4.6792 - val_acc: 0.4286\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3948 - acc: 0.8789 - val_loss: 4.5326 - val_acc: 0.3810\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3875 - acc: 0.8774 - val_loss: 4.6709 - val_acc: 0.4107\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3852 - acc: 0.8909 - val_loss: 4.6583 - val_acc: 0.4048\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4007 - acc: 0.8984 - val_loss: 4.6838 - val_acc: 0.3690\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4434 - acc: 0.8924 - val_loss: 4.9403 - val_acc: 0.4107\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5122 - acc: 0.8655 - val_loss: 5.5668 - val_acc: 0.3810\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6303 - acc: 0.8535 - val_loss: 5.4193 - val_acc: 0.4107\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5495 - acc: 0.8445 - val_loss: 5.5495 - val_acc: 0.3690\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5361 - acc: 0.8774 - val_loss: 5.5604 - val_acc: 0.4107\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5372 - acc: 0.8565 - val_loss: 5.5730 - val_acc: 0.4048\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5225 - acc: 0.8700 - val_loss: 5.8421 - val_acc: 0.4286\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5254 - acc: 0.8864 - val_loss: 6.1579 - val_acc: 0.3571\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5894 - acc: 0.8505 - val_loss: 6.0858 - val_acc: 0.3690\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5225 - acc: 0.8774 - val_loss: 6.1152 - val_acc: 0.4048\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5000 - acc: 0.8774 - val_loss: 5.8913 - val_acc: 0.4167\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4900 - acc: 0.8819 - val_loss: 6.5164 - val_acc: 0.3750\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4682 - acc: 0.8819 - val_loss: 6.0029 - val_acc: 0.4286\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5702 - acc: 0.8625 - val_loss: 6.2641 - val_acc: 0.4107\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5813 - acc: 0.8714 - val_loss: 6.6346 - val_acc: 0.3750\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5510 - acc: 0.8849 - val_loss: 6.3037 - val_acc: 0.3929\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3874 - acc: 0.9103 - val_loss: 6.3676 - val_acc: 0.3988\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3766 - acc: 0.9118 - val_loss: 6.3047 - val_acc: 0.4107\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3925 - acc: 0.8969 - val_loss: 6.8733 - val_acc: 0.4167\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5134 - acc: 0.8774 - val_loss: 7.0911 - val_acc: 0.3750\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5409 - acc: 0.8924 - val_loss: 6.9997 - val_acc: 0.3690\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5150 - acc: 0.9013 - val_loss: 6.9150 - val_acc: 0.4107\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4126 - acc: 0.9208 - val_loss: 7.2016 - val_acc: 0.3988\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4393 - acc: 0.9223 - val_loss: 6.7402 - val_acc: 0.4167\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4973 - acc: 0.9043 - val_loss: 6.9568 - val_acc: 0.3750\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4725 - acc: 0.8954 - val_loss: 7.2881 - val_acc: 0.3869\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5082 - acc: 0.8984 - val_loss: 7.1821 - val_acc: 0.4107\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4454 - acc: 0.8969 - val_loss: 7.1411 - val_acc: 0.4405\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4014 - acc: 0.9088 - val_loss: 7.2966 - val_acc: 0.4167\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5540 - acc: 0.8894 - val_loss: 7.6372 - val_acc: 0.3631\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4900 - acc: 0.8700 - val_loss: 8.3105 - val_acc: 0.3869\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3726 - acc: 0.9163 - val_loss: 8.0236 - val_acc: 0.4107\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4410 - acc: 0.9283 - val_loss: 8.0368 - val_acc: 0.3988\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4255 - acc: 0.8999 - val_loss: 8.5100 - val_acc: 0.3750\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4086 - acc: 0.9148 - val_loss: 8.2261 - val_acc: 0.4107\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3924 - acc: 0.9268 - val_loss: 8.4979 - val_acc: 0.4107\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6260 - acc: 0.8954 - val_loss: 7.9756 - val_acc: 0.4107\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5617 - acc: 0.8834 - val_loss: 8.4124 - val_acc: 0.3452\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5063 - acc: 0.8924 - val_loss: 8.2064 - val_acc: 0.3869\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.8322 - acc: 0.8550 - val_loss: 8.9998 - val_acc: 0.4167\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6151 - acc: 0.8714 - val_loss: 8.4090 - val_acc: 0.3869\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7254 - acc: 0.8864 - val_loss: 8.3807 - val_acc: 0.4167\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4533 - acc: 0.9133 - val_loss: 8.2845 - val_acc: 0.4107\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5213 - acc: 0.8939 - val_loss: 8.5996 - val_acc: 0.4048\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5160 - acc: 0.9058 - val_loss: 8.2674 - val_acc: 0.3988\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3757 - acc: 0.9163 - val_loss: 8.3063 - val_acc: 0.4107\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4129 - acc: 0.9133 - val_loss: 8.1504 - val_acc: 0.3869\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4316 - acc: 0.9193 - val_loss: 7.9662 - val_acc: 0.3929\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5327 - acc: 0.9028 - val_loss: 7.9960 - val_acc: 0.3869\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6339 - acc: 0.8714 - val_loss: 8.6747 - val_acc: 0.3631\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6839 - acc: 0.8819 - val_loss: 8.5886 - val_acc: 0.4167\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5423 - acc: 0.9118 - val_loss: 8.3376 - val_acc: 0.4107\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4671 - acc: 0.9133 - val_loss: 8.2477 - val_acc: 0.3631\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4909 - acc: 0.9058 - val_loss: 8.0333 - val_acc: 0.4107\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4020 - acc: 0.9238 - val_loss: 8.2091 - val_acc: 0.3929\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4698 - acc: 0.9178 - val_loss: 8.4095 - val_acc: 0.3869\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4489 - acc: 0.9088 - val_loss: 7.9469 - val_acc: 0.3929\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3949 - acc: 0.9253 - val_loss: 7.6595 - val_acc: 0.4167\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5591 - acc: 0.8954 - val_loss: 7.7689 - val_acc: 0.4226\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4707 - acc: 0.9043 - val_loss: 8.1236 - val_acc: 0.3988\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4366 - acc: 0.9103 - val_loss: 8.3622 - val_acc: 0.4286\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5530 - acc: 0.9058 - val_loss: 8.9234 - val_acc: 0.3929\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5081 - acc: 0.9013 - val_loss: 9.6519 - val_acc: 0.3750\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5653 - acc: 0.9043 - val_loss: 9.0077 - val_acc: 0.3869\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4871 - acc: 0.9118 - val_loss: 9.0950 - val_acc: 0.3869\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4320 - acc: 0.9238 - val_loss: 9.0826 - val_acc: 0.3869\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4500 - acc: 0.9178 - val_loss: 8.9413 - val_acc: 0.4107\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5527 - acc: 0.9148 - val_loss: 8.6622 - val_acc: 0.3988\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5005 - acc: 0.9223 - val_loss: 8.5270 - val_acc: 0.4048\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4300 - acc: 0.9133 - val_loss: 8.2619 - val_acc: 0.4286\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4745 - acc: 0.9253 - val_loss: 8.8374 - val_acc: 0.3929\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4763 - acc: 0.9073 - val_loss: 8.4480 - val_acc: 0.4048\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3955 - acc: 0.9103 - val_loss: 9.1777 - val_acc: 0.4048\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5319 - acc: 0.9133 - val_loss: 8.9374 - val_acc: 0.4048\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4296 - acc: 0.9103 - val_loss: 9.2871 - val_acc: 0.3988\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4636 - acc: 0.9193 - val_loss: 9.8404 - val_acc: 0.4048\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5241 - acc: 0.9148 - val_loss: 9.1731 - val_acc: 0.3988\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4135 - acc: 0.9268 - val_loss: 8.8527 - val_acc: 0.4345\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.5207 - acc: 0.9163 - val_loss: 10.1118 - val_acc: 0.4048\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6590 - acc: 0.8954 - val_loss: 9.5794 - val_acc: 0.4345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>▁▇▇█▇▆▇▆▆▆▅▂▆▆▄▆▃▆▄▆▄▃▆▄▄▅▄▄▆▆▄▆▄▄▆▅▅▅▅▇</td></tr><tr><td>val_loss</td><td>▁▁▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇█▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>0.43452</td></tr><tr><td>val_loss</td><td>9.57942</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-3</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5p54xesx' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/5p54xesx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230909_203941-5p54xesx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a1ys0pei with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0790674476330251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230909_204035-a1ys0pei</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/a1ys0pei' target=\"_blank\">trim-sweep-4</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/a1ys0pei' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/a1ys0pei</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 17ms/step - loss: 1.4618 - acc: 0.3363 - val_loss: 1.2882 - val_acc: 0.3690\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0599 - acc: 0.5665 - val_loss: 1.7758 - val_acc: 0.4107\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9440 - acc: 0.6428 - val_loss: 1.8436 - val_acc: 0.3452\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9551 - acc: 0.6622 - val_loss: 1.8555 - val_acc: 0.3869\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7875 - acc: 0.7339 - val_loss: 2.6026 - val_acc: 0.3214\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7264 - acc: 0.7384 - val_loss: 2.4026 - val_acc: 0.4107\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6723 - acc: 0.7848 - val_loss: 2.8267 - val_acc: 0.4226\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6460 - acc: 0.7728 - val_loss: 2.6596 - val_acc: 0.3929\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6285 - acc: 0.7862 - val_loss: 2.9302 - val_acc: 0.3869\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5243 - acc: 0.8311 - val_loss: 2.9723 - val_acc: 0.3333\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5540 - acc: 0.8281 - val_loss: 3.5464 - val_acc: 0.3750\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6622 - acc: 0.8102 - val_loss: 4.0924 - val_acc: 0.3869\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7900 - acc: 0.7608 - val_loss: 3.8900 - val_acc: 0.3750\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6602 - acc: 0.8102 - val_loss: 3.9264 - val_acc: 0.3869\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4520 - acc: 0.8565 - val_loss: 4.0556 - val_acc: 0.3690\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4846 - acc: 0.8625 - val_loss: 4.2546 - val_acc: 0.3750\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6810 - acc: 0.8146 - val_loss: 5.2206 - val_acc: 0.3750\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6380 - acc: 0.8356 - val_loss: 4.9844 - val_acc: 0.3690\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5611 - acc: 0.8535 - val_loss: 5.0277 - val_acc: 0.3452\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7165 - acc: 0.8236 - val_loss: 6.0702 - val_acc: 0.3810\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6043 - acc: 0.8550 - val_loss: 5.1058 - val_acc: 0.3869\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5571 - acc: 0.8700 - val_loss: 5.3637 - val_acc: 0.3750\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.4480 - acc: 0.8834 - val_loss: 5.0063 - val_acc: 0.3810\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5082 - acc: 0.8610 - val_loss: 5.3820 - val_acc: 0.3571\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6607 - acc: 0.8565 - val_loss: 6.1523 - val_acc: 0.3631\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6363 - acc: 0.8490 - val_loss: 5.6299 - val_acc: 0.3690\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6370 - acc: 0.8565 - val_loss: 5.9224 - val_acc: 0.3452\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5274 - acc: 0.8759 - val_loss: 5.8406 - val_acc: 0.3452\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.5342 - acc: 0.8969 - val_loss: 5.8896 - val_acc: 0.3333\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.5667 - acc: 0.8894 - val_loss: 6.7929 - val_acc: 0.3452\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5441 - acc: 0.8640 - val_loss: 5.9422 - val_acc: 0.3631\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.5892 - acc: 0.8759 - val_loss: 5.9713 - val_acc: 0.3810\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5971 - acc: 0.8670 - val_loss: 6.2000 - val_acc: 0.3452\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.4802 - acc: 0.8939 - val_loss: 7.2744 - val_acc: 0.3452\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.5781 - acc: 0.8954 - val_loss: 7.4643 - val_acc: 0.3393\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.5124 - acc: 0.8759 - val_loss: 6.9941 - val_acc: 0.3274\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6072 - acc: 0.8700 - val_loss: 7.4833 - val_acc: 0.3571\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5504 - acc: 0.9043 - val_loss: 7.6046 - val_acc: 0.3393\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5971 - acc: 0.8774 - val_loss: 7.4111 - val_acc: 0.3571\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.6491 - acc: 0.8729 - val_loss: 7.4805 - val_acc: 0.3631\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.5214 - acc: 0.8879 - val_loss: 7.0881 - val_acc: 0.3214\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.8161 - acc: 0.8505 - val_loss: 7.4753 - val_acc: 0.3750\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7945 - acc: 0.8640 - val_loss: 8.4915 - val_acc: 0.3631\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.9052 - acc: 0.8341 - val_loss: 8.6530 - val_acc: 0.3155\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9141 - acc: 0.8311 - val_loss: 8.6070 - val_acc: 0.3571\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.9506 - acc: 0.8401 - val_loss: 8.1668 - val_acc: 0.3810\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.8295 - acc: 0.8729 - val_loss: 8.5507 - val_acc: 0.3631\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8338 - acc: 0.8550 - val_loss: 9.2106 - val_acc: 0.3690\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7070 - acc: 0.8894 - val_loss: 9.0057 - val_acc: 0.3571\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6037 - acc: 0.8909 - val_loss: 8.4273 - val_acc: 0.3869\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5841 - acc: 0.8969 - val_loss: 8.2961 - val_acc: 0.3690\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6115 - acc: 0.9028 - val_loss: 8.1084 - val_acc: 0.3810\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5860 - acc: 0.8939 - val_loss: 7.8969 - val_acc: 0.3452\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7587 - acc: 0.8640 - val_loss: 8.3785 - val_acc: 0.3512\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6626 - acc: 0.8670 - val_loss: 9.2340 - val_acc: 0.3690\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5656 - acc: 0.8939 - val_loss: 9.9915 - val_acc: 0.3750\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8591 - acc: 0.8625 - val_loss: 9.7798 - val_acc: 0.3333\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7582 - acc: 0.8744 - val_loss: 9.5129 - val_acc: 0.3512\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7621 - acc: 0.8924 - val_loss: 10.1088 - val_acc: 0.3512\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7282 - acc: 0.8670 - val_loss: 9.2007 - val_acc: 0.3690\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7989 - acc: 0.8909 - val_loss: 9.1297 - val_acc: 0.3631\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4965 - acc: 0.9043 - val_loss: 10.5890 - val_acc: 0.3333\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5838 - acc: 0.9013 - val_loss: 9.7863 - val_acc: 0.3512\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6057 - acc: 0.9073 - val_loss: 9.6782 - val_acc: 0.3631\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6835 - acc: 0.8954 - val_loss: 9.8802 - val_acc: 0.3512\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6718 - acc: 0.8714 - val_loss: 10.2004 - val_acc: 0.3810\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5735 - acc: 0.9073 - val_loss: 10.9094 - val_acc: 0.3393\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6735 - acc: 0.8924 - val_loss: 10.0875 - val_acc: 0.3571\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7939 - acc: 0.8894 - val_loss: 10.3991 - val_acc: 0.3333\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6301 - acc: 0.8984 - val_loss: 10.5734 - val_acc: 0.3512\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6529 - acc: 0.9133 - val_loss: 11.0315 - val_acc: 0.3393\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6372 - acc: 0.8939 - val_loss: 10.3595 - val_acc: 0.3571\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6110 - acc: 0.9013 - val_loss: 10.7821 - val_acc: 0.3512\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5379 - acc: 0.9058 - val_loss: 10.3031 - val_acc: 0.3631\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5830 - acc: 0.9163 - val_loss: 11.2026 - val_acc: 0.3750\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7610 - acc: 0.8939 - val_loss: 11.0724 - val_acc: 0.3512\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7041 - acc: 0.8984 - val_loss: 10.8084 - val_acc: 0.3512\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5351 - acc: 0.9193 - val_loss: 12.0131 - val_acc: 0.3274\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6962 - acc: 0.8909 - val_loss: 11.2224 - val_acc: 0.3810\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6454 - acc: 0.9163 - val_loss: 11.7427 - val_acc: 0.3452\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.5209 - acc: 0.9327 - val_loss: 11.4471 - val_acc: 0.3452\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7556 - acc: 0.8954 - val_loss: 10.6268 - val_acc: 0.3690\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5068 - acc: 0.9238 - val_loss: 10.3119 - val_acc: 0.3512\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7126 - acc: 0.9088 - val_loss: 10.3902 - val_acc: 0.3810\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7944 - acc: 0.8789 - val_loss: 10.8419 - val_acc: 0.3571\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6966 - acc: 0.9073 - val_loss: 10.9210 - val_acc: 0.3512\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5410 - acc: 0.9163 - val_loss: 11.7373 - val_acc: 0.3452\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8624 - acc: 0.8894 - val_loss: 10.4293 - val_acc: 0.3393\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6255 - acc: 0.8969 - val_loss: 10.1469 - val_acc: 0.3750\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6647 - acc: 0.8984 - val_loss: 11.3910 - val_acc: 0.3631\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5158 - acc: 0.9148 - val_loss: 10.6213 - val_acc: 0.3333\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5132 - acc: 0.9193 - val_loss: 10.7652 - val_acc: 0.3631\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6268 - acc: 0.8969 - val_loss: 10.8106 - val_acc: 0.3512\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7475 - acc: 0.8864 - val_loss: 11.7484 - val_acc: 0.3631\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5423 - acc: 0.9297 - val_loss: 12.4618 - val_acc: 0.3571\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7051 - acc: 0.9043 - val_loss: 12.3039 - val_acc: 0.3512\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.5824 - acc: 0.9297 - val_loss: 11.9239 - val_acc: 0.3452\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.6828 - acc: 0.9133 - val_loss: 12.6624 - val_acc: 0.3452\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.5262 - acc: 0.9268 - val_loss: 12.5541 - val_acc: 0.3333\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7286 - acc: 0.9028 - val_loss: 13.0586 - val_acc: 0.3512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>▅▃█▇▅▅▅▅▆▆▅▃▄▃▂▄▁▁▆▄▅▄▅▄▄▄▃▂▄▄▄▆▅▆▃▅▄▄▃▄</td></tr><tr><td>val_loss</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▅▄▅▄▅▅▆▅▅▆▆▆▆▇▆▆▆▇▇▇▆▇▆▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>0.35119</td></tr><tr><td>val_loss</td><td>13.05865</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sweep-4</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/a1ys0pei' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/a1ys0pei</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230909_204035-a1ys0pei\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hd4e465l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: Poems\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09055556227579983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\wandb\\run-20230909_204112-hd4e465l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/hd4e465l' target=\"_blank\">celestial-sweep-5</a></strong> to <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/sweeps/77qlslpj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/hd4e465l' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/hd4e465l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')\n",
      "c:\\Users\\Jesli's Laptop\\Desktop\\Acads\\MLO\\mlo-final-project\\code\\model.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jesli's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 18ms/step - loss: 1.5657 - acc: 0.3019 - val_loss: 1.4709 - val_acc: 0.3929\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.1201 - acc: 0.5366 - val_loss: 1.5328 - val_acc: 0.3750\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8668 - acc: 0.6831 - val_loss: 1.7696 - val_acc: 0.4107\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9867 - acc: 0.6801 - val_loss: 2.1333 - val_acc: 0.3929\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9091 - acc: 0.6921 - val_loss: 2.5733 - val_acc: 0.4107\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9019 - acc: 0.7205 - val_loss: 2.8820 - val_acc: 0.3274\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8254 - acc: 0.7250 - val_loss: 3.1038 - val_acc: 0.3036\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5971 - acc: 0.8042 - val_loss: 3.4810 - val_acc: 0.3452\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6736 - acc: 0.7862 - val_loss: 3.7569 - val_acc: 0.3393\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.8897 - acc: 0.7773 - val_loss: 4.4043 - val_acc: 0.4167\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7951 - acc: 0.7967 - val_loss: 4.4087 - val_acc: 0.2917\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6189 - acc: 0.8161 - val_loss: 4.6000 - val_acc: 0.3214\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6326 - acc: 0.8117 - val_loss: 4.9459 - val_acc: 0.3214\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7265 - acc: 0.8281 - val_loss: 5.4899 - val_acc: 0.3274\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7611 - acc: 0.7952 - val_loss: 5.1236 - val_acc: 0.3274\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6887 - acc: 0.8281 - val_loss: 6.1917 - val_acc: 0.2619\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7617 - acc: 0.8146 - val_loss: 6.2435 - val_acc: 0.2560\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6881 - acc: 0.8296 - val_loss: 6.3797 - val_acc: 0.3274\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8101 - acc: 0.8416 - val_loss: 6.4744 - val_acc: 0.3452\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6934 - acc: 0.8460 - val_loss: 6.5393 - val_acc: 0.3214\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8647 - acc: 0.8311 - val_loss: 6.8796 - val_acc: 0.3333\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7920 - acc: 0.8266 - val_loss: 7.5086 - val_acc: 0.2798\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8637 - acc: 0.8326 - val_loss: 7.3716 - val_acc: 0.3036\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.8473 - acc: 0.8326 - val_loss: 7.5636 - val_acc: 0.3869\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9348 - acc: 0.8416 - val_loss: 8.9765 - val_acc: 0.3095\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9387 - acc: 0.8072 - val_loss: 8.2010 - val_acc: 0.3512\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9175 - acc: 0.8326 - val_loss: 9.1459 - val_acc: 0.2381\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7506 - acc: 0.8416 - val_loss: 8.4588 - val_acc: 0.3631\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6294 - acc: 0.8819 - val_loss: 9.5276 - val_acc: 0.2976\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8953 - acc: 0.8490 - val_loss: 8.2038 - val_acc: 0.3274\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.6582 - acc: 0.8595 - val_loss: 8.7033 - val_acc: 0.3393\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.8747 - acc: 0.8430 - val_loss: 8.7221 - val_acc: 0.3929\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8094 - acc: 0.8535 - val_loss: 9.3753 - val_acc: 0.2976\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.8176 - acc: 0.8670 - val_loss: 9.2282 - val_acc: 0.3214\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.9470 - acc: 0.8386 - val_loss: 9.7858 - val_acc: 0.3452\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.8414 - acc: 0.8386 - val_loss: 9.8940 - val_acc: 0.2976\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7042 - acc: 0.8804 - val_loss: 9.9502 - val_acc: 0.2679\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0143 - acc: 0.8401 - val_loss: 9.9487 - val_acc: 0.3452\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8274 - acc: 0.8670 - val_loss: 10.9048 - val_acc: 0.2976\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0995 - acc: 0.8505 - val_loss: 10.3697 - val_acc: 0.3095\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7432 - acc: 0.8700 - val_loss: 10.8218 - val_acc: 0.2857\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8067 - acc: 0.8714 - val_loss: 11.1127 - val_acc: 0.3631\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9148 - acc: 0.8565 - val_loss: 10.2102 - val_acc: 0.3036\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6761 - acc: 0.8729 - val_loss: 10.4544 - val_acc: 0.3036\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8859 - acc: 0.8939 - val_loss: 9.8773 - val_acc: 0.3690\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8997 - acc: 0.8565 - val_loss: 10.0094 - val_acc: 0.2917\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6269 - acc: 0.8849 - val_loss: 10.7343 - val_acc: 0.2798\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8566 - acc: 0.8714 - val_loss: 10.9048 - val_acc: 0.3036\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6862 - acc: 0.8879 - val_loss: 10.7458 - val_acc: 0.2679\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6889 - acc: 0.8849 - val_loss: 10.9351 - val_acc: 0.3214\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8442 - acc: 0.8565 - val_loss: 11.7229 - val_acc: 0.2917\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8747 - acc: 0.8729 - val_loss: 11.5033 - val_acc: 0.3036\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6217 - acc: 0.8894 - val_loss: 12.4296 - val_acc: 0.3333\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7810 - acc: 0.8849 - val_loss: 11.6345 - val_acc: 0.3155\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8902 - acc: 0.8685 - val_loss: 11.6104 - val_acc: 0.3214\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6385 - acc: 0.8969 - val_loss: 12.1154 - val_acc: 0.3452\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0732 - acc: 0.8670 - val_loss: 12.1943 - val_acc: 0.3452\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.9506 - acc: 0.8789 - val_loss: 12.4713 - val_acc: 0.3095\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.9725 - acc: 0.8685 - val_loss: 12.5092 - val_acc: 0.3214\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8295 - acc: 0.9013 - val_loss: 12.6436 - val_acc: 0.3214\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7467 - acc: 0.8759 - val_loss: 13.1196 - val_acc: 0.4167\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9411 - acc: 0.8595 - val_loss: 12.8789 - val_acc: 0.3274\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9251 - acc: 0.8744 - val_loss: 11.7913 - val_acc: 0.3452\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7188 - acc: 0.8744 - val_loss: 12.3976 - val_acc: 0.3214\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8723 - acc: 0.9013 - val_loss: 12.9303 - val_acc: 0.2798\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6858 - acc: 0.8939 - val_loss: 11.9831 - val_acc: 0.3274\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8882 - acc: 0.8610 - val_loss: 12.2994 - val_acc: 0.3452\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8309 - acc: 0.8834 - val_loss: 12.9004 - val_acc: 0.3333\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7022 - acc: 0.8909 - val_loss: 14.2021 - val_acc: 0.3095\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.9951 - acc: 0.8819 - val_loss: 13.7923 - val_acc: 0.3393\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9336 - acc: 0.8744 - val_loss: 14.3779 - val_acc: 0.2917\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8581 - acc: 0.8879 - val_loss: 13.6306 - val_acc: 0.3393\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7755 - acc: 0.8909 - val_loss: 13.7132 - val_acc: 0.3393\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7855 - acc: 0.8984 - val_loss: 13.7147 - val_acc: 0.3095\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8965 - acc: 0.8729 - val_loss: 14.3451 - val_acc: 0.3452\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.1072 - acc: 0.8565 - val_loss: 15.0894 - val_acc: 0.3274\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.2595 - acc: 0.8595 - val_loss: 15.8796 - val_acc: 0.3214\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9980 - acc: 0.8849 - val_loss: 15.5591 - val_acc: 0.3333\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9615 - acc: 0.8759 - val_loss: 15.9128 - val_acc: 0.3333\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.9747 - acc: 0.8879 - val_loss: 15.1144 - val_acc: 0.3393\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.8051 - acc: 0.8909 - val_loss: 16.5392 - val_acc: 0.2560\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.2005 - acc: 0.8610 - val_loss: 15.2059 - val_acc: 0.3214\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9940 - acc: 0.8744 - val_loss: 15.9681 - val_acc: 0.3155\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9119 - acc: 0.8939 - val_loss: 16.2256 - val_acc: 0.3274\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0705 - acc: 0.8924 - val_loss: 16.2494 - val_acc: 0.3214\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9755 - acc: 0.8924 - val_loss: 15.4373 - val_acc: 0.3512\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0312 - acc: 0.8759 - val_loss: 15.8351 - val_acc: 0.3036\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0204 - acc: 0.8879 - val_loss: 15.8452 - val_acc: 0.2917\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.8314 - acc: 0.8954 - val_loss: 15.5414 - val_acc: 0.2917\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.5781 - acc: 0.9118 - val_loss: 15.2619 - val_acc: 0.3036\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7748 - acc: 0.9013 - val_loss: 15.9919 - val_acc: 0.2857\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7554 - acc: 0.9073 - val_loss: 15.6053 - val_acc: 0.3512\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.0176 - acc: 0.8714 - val_loss: 16.3404 - val_acc: 0.3393\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.2046 - acc: 0.8759 - val_loss: 15.9785 - val_acc: 0.3393\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7746 - acc: 0.9028 - val_loss: 17.8113 - val_acc: 0.3452\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.9868 - acc: 0.9073 - val_loss: 17.1232 - val_acc: 0.3393\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9654 - acc: 0.8969 - val_loss: 16.6937 - val_acc: 0.3393\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0364 - acc: 0.8834 - val_loss: 17.2386 - val_acc: 0.3333\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8424 - acc: 0.8924 - val_loss: 17.3791 - val_acc: 0.3155\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7956 - acc: 0.9073 - val_loss: 16.6082 - val_acc: 0.3393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>▇█▄▅▂▄▁▄▄▃▅▆▄▄▃▃▂▃▂▁▂▃▅▄█▄▅▃▄▃▄▄▄▄▃▂▅▄▄▄</td></tr><tr><td>val_loss</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇██▇██▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_acc</td><td>0.33929</td></tr><tr><td>val_loss</td><td>16.60823</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-5</strong> at: <a href='https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/hd4e465l' target=\"_blank\">https://wandb.ai/msds_mlops2023_lt2/mlo-final-project/runs/hd4e465l</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230909_204112-hd4e465l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define hyperparam search function\n",
    "def hyperparam_search(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        # use config params\n",
    "        learning_rate = config.learning_rate\n",
    "        optimizer = config.optimizer\n",
    "        embedding_dim = config.embedding_dim\n",
    "        epochs = config.epochs\n",
    "\n",
    "        # define model\n",
    "        _model = poem_classifier_model()\n",
    "\n",
    "        _model.load_data()\n",
    "        _model.preprocess()\n",
    "        _model.train(embd_dim=embedding_dim, epochs=epochs, lr=learning_rate, optimizer=optimizer)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            wandb.log({\"val_loss\": _model.trained_model.history['val_loss'][i], \n",
    "                       \"val_acc\": _model.trained_model.history['val_acc'][i]})\n",
    "\n",
    "wandb.agent(sweep_id, hyperparam_search, count=5) # count - num iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
