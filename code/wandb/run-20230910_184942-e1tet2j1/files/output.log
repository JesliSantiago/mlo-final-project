c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/30
21/21 [==============================] - 1s 28ms/step - loss: 1.3669 - acc: 0.3333 - val_loss: 1.4990 - val_acc: 0.3036
Epoch 2/30
21/21 [==============================] - 0s 22ms/step - loss: 1.1602 - acc: 0.4828 - val_loss: 1.3042 - val_acc: 0.3571
Epoch 3/30
21/21 [==============================] - 0s 22ms/step - loss: 0.8827 - acc: 0.6607 - val_loss: 1.5049 - val_acc: 0.3750
Epoch 4/30
21/21 [==============================] - 0s 22ms/step - loss: 0.7489 - acc: 0.7115 - val_loss: 1.6263 - val_acc: 0.3452
Epoch 5/30
21/21 [==============================] - 0s 22ms/step - loss: 0.6307 - acc: 0.7638 - val_loss: 1.8153 - val_acc: 0.3810
Epoch 6/30
21/21 [==============================] - 0s 21ms/step - loss: 0.5764 - acc: 0.7877 - val_loss: 2.0118 - val_acc: 0.3452
Epoch 7/30
21/21 [==============================] - 0s 20ms/step - loss: 0.5237 - acc: 0.8087 - val_loss: 2.0693 - val_acc: 0.3452
Epoch 8/30
21/21 [==============================] - 0s 21ms/step - loss: 0.4586 - acc: 0.8311 - val_loss: 2.2774 - val_acc: 0.3393
Epoch 9/30
21/21 [==============================] - 0s 24ms/step - loss: 0.4214 - acc: 0.8535 - val_loss: 2.4483 - val_acc: 0.3333
Epoch 10/30
21/21 [==============================] - 0s 23ms/step - loss: 0.3808 - acc: 0.8610 - val_loss: 2.6437 - val_acc: 0.3393
Epoch 11/30
21/21 [==============================] - 0s 22ms/step - loss: 0.4190 - acc: 0.8535 - val_loss: 2.8871 - val_acc: 0.3393
Epoch 12/30
21/21 [==============================] - 0s 21ms/step - loss: 0.3378 - acc: 0.8909 - val_loss: 2.8824 - val_acc: 0.3393
Epoch 13/30
21/21 [==============================] - 0s 22ms/step - loss: 0.3350 - acc: 0.8819 - val_loss: 3.2478 - val_acc: 0.3512
Epoch 14/30
21/21 [==============================] - 0s 22ms/step - loss: 0.2691 - acc: 0.8969 - val_loss: 3.3693 - val_acc: 0.3274
Epoch 15/30
21/21 [==============================] - 0s 21ms/step - loss: 0.2983 - acc: 0.8924 - val_loss: 3.4146 - val_acc: 0.3571
Epoch 16/30
21/21 [==============================] - 0s 21ms/step - loss: 0.4001 - acc: 0.8610 - val_loss: 3.9006 - val_acc: 0.3155
Epoch 17/30
21/21 [==============================] - 0s 20ms/step - loss: 0.2668 - acc: 0.9193 - val_loss: 3.8243 - val_acc: 0.3452
Epoch 18/30
21/21 [==============================] - 0s 21ms/step - loss: 0.2755 - acc: 0.9073 - val_loss: 3.8527 - val_acc: 0.3155
Epoch 19/30
21/21 [==============================] - 0s 22ms/step - loss: 0.2343 - acc: 0.9163 - val_loss: 4.1065 - val_acc: 0.3393
Epoch 20/30
21/21 [==============================] - 0s 23ms/step - loss: 0.2342 - acc: 0.9208 - val_loss: 4.1081 - val_acc: 0.3512
Epoch 21/30
21/21 [==============================] - 0s 21ms/step - loss: 0.2827 - acc: 0.9223 - val_loss: 4.2167 - val_acc: 0.3452
Epoch 22/30
21/21 [==============================] - 0s 21ms/step - loss: 0.2536 - acc: 0.9208 - val_loss: 4.3427 - val_acc: 0.2738
Epoch 23/30
21/21 [==============================] - 0s 21ms/step - loss: 0.3041 - acc: 0.8999 - val_loss: 4.3621 - val_acc: 0.3571
Epoch 24/30
21/21 [==============================] - 0s 21ms/step - loss: 0.2928 - acc: 0.9193 - val_loss: 4.4272 - val_acc: 0.3333
Epoch 25/30
21/21 [==============================] - 0s 23ms/step - loss: 0.3039 - acc: 0.9043 - val_loss: 4.4899 - val_acc: 0.3631
Epoch 26/30
21/21 [==============================] - 0s 22ms/step - loss: 0.2756 - acc: 0.9253 - val_loss: 4.7114 - val_acc: 0.3690
Epoch 27/30
21/21 [==============================] - 0s 20ms/step - loss: 0.2284 - acc: 0.9268 - val_loss: 4.6243 - val_acc: 0.3571
Epoch 28/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2187 - acc: 0.9387 - val_loss: 4.8050 - val_acc: 0.3036
Epoch 29/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3270 - acc: 0.9073 - val_loss: 4.8385 - val_acc: 0.2976
Epoch 30/30
21/21 [==============================] - 0s 20ms/step - loss: 0.2222 - acc: 0.9372 - val_loss: 4.7800 - val_acc: 0.3155
{'loss': [1.366919994354248, 1.1602405309677124, 0.8826553225517273, 0.7488875985145569, 0.6306574940681458, 0.576412558555603, 0.523651123046875, 0.4585898816585541, 0.42137107253074646, 0.38079413771629333, 0.41899725794792175, 0.3377574384212494, 0.3350001275539398, 0.2690722346305847, 0.29832929372787476, 0.4001457095146179, 0.2667897641658783, 0.2754935324192047, 0.23426087200641632, 0.23416931927204132, 0.28274568915367126, 0.2536086142063141, 0.30409789085388184, 0.2928147614002228, 0.3038685917854309, 0.2755524814128876, 0.22841840982437134, 0.2187146693468094, 0.3270235061645508, 0.2222256064414978], 'acc': [0.3333333432674408, 0.4828101694583893, 0.6606875658035278, 0.7115097045898438, 0.7638266086578369, 0.7877429127693176, 0.8086696267127991, 0.8310911655426025, 0.853512704372406, 0.8609865307807922, 0.853512704372406, 0.8908818960189819, 0.8819133043289185, 0.8968609571456909, 0.8923766613006592, 0.8609865307807922, 0.9192824959754944, 0.9073243737220764, 0.9162929654121399, 0.9207772612571716, 0.9222720265388489, 0.9207772612571716, 0.8998505473136902, 0.9192824959754944, 0.9043348431587219, 0.9252615571022034, 0.9267563819885254, 0.9387145042419434, 0.9073243737220764, 0.9372197389602661], 'val_loss': [1.4990391731262207, 1.3042134046554565, 1.5048829317092896, 1.6262810230255127, 1.8152716159820557, 2.0118305683135986, 2.0692996978759766, 2.2774009704589844, 2.448282241821289, 2.6436538696289062, 2.8871326446533203, 2.8824410438537598, 3.2478396892547607, 3.3693041801452637, 3.4146077632904053, 3.900609254837036, 3.8243396282196045, 3.852729082107544, 4.106499671936035, 4.108057498931885, 4.216733455657959, 4.342713356018066, 4.362145900726318, 4.427151203155518, 4.489923477172852, 4.7114386558532715, 4.624294757843018, 4.805020809173584, 4.838451862335205, 4.780049800872803], 'val_acc': [0.3035714328289032, 0.3571428656578064, 0.375, 0.3452380895614624, 0.380952388048172, 0.3452380895614624, 0.3452380895614624, 0.3392857015132904, 0.3333333432674408, 0.3392857015132904, 0.3392857015132904, 0.3392857015132904, 0.3511904776096344, 0.3273809552192688, 0.3571428656578064, 0.3154761791229248, 0.3452380895614624, 0.3154761791229248, 0.3392857015132904, 0.3511904776096344, 0.3452380895614624, 0.2738095223903656, 0.3571428656578064, 0.3333333432674408, 0.363095223903656, 0.369047611951828, 0.3571428656578064, 0.3035714328289032, 0.2976190447807312, 0.3154761791229248]}
5/5 [==============================] - 0s 3ms/step - loss: 4.9393 - acc: 0.3400