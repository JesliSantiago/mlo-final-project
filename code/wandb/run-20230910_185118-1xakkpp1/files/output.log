Epoch 1/30
21/21 [==============================] - 1s 25ms/step - loss: 1.7131 - acc: 0.2870 - val_loss: 1.3882 - val_acc: 0.3571
Epoch 2/30
21/21 [==============================] - 0s 19ms/step - loss: 1.1972 - acc: 0.5306 - val_loss: 1.5662 - val_acc: 0.4167
Epoch 3/30
13/21 [=================>............] - ETA: 0s - loss: 1.0915 - acc: 0.6274
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
21/21 [==============================] - 0s 19ms/step - loss: 1.2063 - acc: 0.5919 - val_loss: 1.9246 - val_acc: 0.3929
Epoch 4/30
21/21 [==============================] - 0s 19ms/step - loss: 0.9770 - acc: 0.6861 - val_loss: 2.7117 - val_acc: 0.3810
Epoch 5/30
21/21 [==============================] - 0s 19ms/step - loss: 0.9294 - acc: 0.6981 - val_loss: 2.8254 - val_acc: 0.3750
Epoch 6/30
21/21 [==============================] - 0s 19ms/step - loss: 0.9387 - acc: 0.7280 - val_loss: 3.0318 - val_acc: 0.3988
Epoch 7/30
21/21 [==============================] - 0s 19ms/step - loss: 0.9676 - acc: 0.7444 - val_loss: 3.6906 - val_acc: 0.3571
Epoch 8/30
21/21 [==============================] - 0s 19ms/step - loss: 1.1004 - acc: 0.7414 - val_loss: 4.6963 - val_acc: 0.3631
Epoch 9/30
21/21 [==============================] - 0s 19ms/step - loss: 1.5240 - acc: 0.7115 - val_loss: 5.2486 - val_acc: 0.3155
Epoch 10/30
21/21 [==============================] - 0s 20ms/step - loss: 1.1756 - acc: 0.7758 - val_loss: 5.1832 - val_acc: 0.4226
Epoch 11/30
21/21 [==============================] - 0s 19ms/step - loss: 1.0080 - acc: 0.8012 - val_loss: 6.2227 - val_acc: 0.3155
Epoch 12/30
21/21 [==============================] - 0s 20ms/step - loss: 1.0439 - acc: 0.7937 - val_loss: 6.3451 - val_acc: 0.3631
Epoch 13/30
21/21 [==============================] - 0s 21ms/step - loss: 1.4619 - acc: 0.7414 - val_loss: 8.6715 - val_acc: 0.3452
Epoch 14/30
21/21 [==============================] - 0s 19ms/step - loss: 1.4179 - acc: 0.7758 - val_loss: 6.6926 - val_acc: 0.3869
Epoch 15/30
21/21 [==============================] - 0s 19ms/step - loss: 1.0546 - acc: 0.8117 - val_loss: 6.7003 - val_acc: 0.3810
Epoch 16/30
21/21 [==============================] - 0s 19ms/step - loss: 1.0260 - acc: 0.8206 - val_loss: 7.5764 - val_acc: 0.4048
Epoch 17/30
21/21 [==============================] - 0s 20ms/step - loss: 1.4998 - acc: 0.7892 - val_loss: 8.3354 - val_acc: 0.3512
Epoch 18/30
21/21 [==============================] - 0s 19ms/step - loss: 1.0486 - acc: 0.8445 - val_loss: 8.2164 - val_acc: 0.3690
Epoch 19/30
21/21 [==============================] - 0s 19ms/step - loss: 1.1809 - acc: 0.8266 - val_loss: 8.6425 - val_acc: 0.3571
Epoch 20/30
21/21 [==============================] - 0s 20ms/step - loss: 1.2562 - acc: 0.8326 - val_loss: 8.5070 - val_acc: 0.3869
Epoch 21/30
21/21 [==============================] - 0s 19ms/step - loss: 1.5303 - acc: 0.7922 - val_loss: 9.4658 - val_acc: 0.3869
Epoch 22/30
21/21 [==============================] - 0s 20ms/step - loss: 1.6154 - acc: 0.8042 - val_loss: 10.9975 - val_acc: 0.4226
Epoch 23/30
21/21 [==============================] - 0s 19ms/step - loss: 1.6976 - acc: 0.8072 - val_loss: 11.8199 - val_acc: 0.3155
Epoch 24/30
21/21 [==============================] - 0s 19ms/step - loss: 1.3006 - acc: 0.8460 - val_loss: 10.6278 - val_acc: 0.3571
Epoch 25/30
21/21 [==============================] - 0s 19ms/step - loss: 1.1963 - acc: 0.8490 - val_loss: 11.1532 - val_acc: 0.3155
Epoch 26/30
21/21 [==============================] - 0s 19ms/step - loss: 1.3286 - acc: 0.8401 - val_loss: 13.4398 - val_acc: 0.2857
Epoch 27/30
21/21 [==============================] - 0s 19ms/step - loss: 1.4679 - acc: 0.8146 - val_loss: 11.2587 - val_acc: 0.3750
Epoch 28/30
21/21 [==============================] - 0s 19ms/step - loss: 1.3200 - acc: 0.8460 - val_loss: 15.0522 - val_acc: 0.3333
Epoch 29/30
21/21 [==============================] - 0s 20ms/step - loss: 1.4011 - acc: 0.8610 - val_loss: 12.3202 - val_acc: 0.3750
Epoch 30/30
21/21 [==============================] - 0s 20ms/step - loss: 1.5431 - acc: 0.8371 - val_loss: 13.4338 - val_acc: 0.2738
{'loss': [1.713120937347412, 1.1972267627716064, 1.2062808275222778, 0.9769604802131653, 0.9293885231018066, 0.938680112361908, 0.967563807964325, 1.1003732681274414, 1.5239688158035278, 1.175597906112671, 1.0080400705337524, 1.0438541173934937, 1.4619215726852417, 1.4179329872131348, 1.0546129941940308, 1.0259616374969482, 1.4998430013656616, 1.0485637187957764, 1.1809089183807373, 1.2561752796173096, 1.5303105115890503, 1.6154128313064575, 1.697646975517273, 1.300642490386963, 1.1963444948196411, 1.328562617301941, 1.467905044555664, 1.3200287818908691, 1.401142954826355, 1.5431252717971802], 'acc': [0.286995530128479, 0.5306427478790283, 0.591928243637085, 0.6860986351966858, 0.6980568170547485, 0.7279521822929382, 0.7443946003913879, 0.7414050698280334, 0.7115097045898438, 0.7757847309112549, 0.8011958003044128, 0.7937219738960266, 0.7414050698280334, 0.7757847309112549, 0.8116592168807983, 0.8206278085708618, 0.7892376780509949, 0.8445441126823425, 0.8266068696975708, 0.8325859308242798, 0.7922272086143494, 0.8041853308677673, 0.8071748614311218, 0.8460388779640198, 0.8490284085273743, 0.8400598168373108, 0.8146487474441528, 0.8460388779640198, 0.8609865307807922, 0.8370702266693115], 'val_loss': [1.3881819248199463, 1.566163420677185, 1.9246222972869873, 2.71171498298645, 2.825429916381836, 3.0318386554718018, 3.6906039714813232, 4.696320533752441, 5.248559474945068, 5.183243274688721, 6.222707748413086, 6.345067501068115, 8.671452522277832, 6.692553520202637, 6.700252532958984, 7.576350688934326, 8.335360527038574, 8.216367721557617, 8.642546653747559, 8.507001876831055, 9.465827941894531, 10.99749755859375, 11.819914817810059, 10.627787590026855, 11.153191566467285, 13.439794540405273, 11.258657455444336, 15.05224323272705, 12.320235252380371, 13.433793067932129], 'val_acc': [0.3571428656578064, 0.4166666567325592, 0.3928571343421936, 0.380952388048172, 0.375, 0.3988095223903656, 0.3571428656578064, 0.363095223903656, 0.3154761791229248, 0.4226190447807312, 0.3154761791229248, 0.363095223903656, 0.3452380895614624, 0.386904776096344, 0.380952388048172, 0.4047619104385376, 0.3511904776096344, 0.369047611951828, 0.3571428656578064, 0.386904776096344, 0.386904776096344, 0.4226190447807312, 0.3154761791229248, 0.3571428656578064, 0.3154761791229248, 0.2857142984867096, 0.375, 0.3333333432674408, 0.375, 0.2738095223903656]}
5/5 [==============================] - 0s 3ms/step - loss: 16.3708 - acc: 0.2600