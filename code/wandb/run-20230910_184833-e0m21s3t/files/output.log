c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/30
21/21 [==============================] - 1s 24ms/step - loss: 1.3856 - acc: 0.3438 - val_loss: 1.3210 - val_acc: 0.3690
Epoch 2/30
21/21 [==============================] - 0s 19ms/step - loss: 1.1003 - acc: 0.5097 - val_loss: 1.2868 - val_acc: 0.4107
Epoch 3/30
21/21 [==============================] - 0s 19ms/step - loss: 0.8624 - acc: 0.6607 - val_loss: 1.6990 - val_acc: 0.4048
Epoch 4/30
21/21 [==============================] - 0s 19ms/step - loss: 0.6974 - acc: 0.7160 - val_loss: 1.8025 - val_acc: 0.4107
Epoch 5/30
21/21 [==============================] - 0s 19ms/step - loss: 0.5562 - acc: 0.7833 - val_loss: 2.0100 - val_acc: 0.4107
Epoch 6/30
21/21 [==============================] - 0s 18ms/step - loss: 0.4759 - acc: 0.8117 - val_loss: 2.3427 - val_acc: 0.4167
Epoch 7/30
21/21 [==============================] - 0s 18ms/step - loss: 0.5133 - acc: 0.8132 - val_loss: 2.9105 - val_acc: 0.4048
Epoch 8/30
21/21 [==============================] - 0s 19ms/step - loss: 0.5551 - acc: 0.7833 - val_loss: 2.7190 - val_acc: 0.3929
Epoch 9/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3723 - acc: 0.8670 - val_loss: 2.9955 - val_acc: 0.3631
Epoch 10/30
21/21 [==============================] - 0s 18ms/step - loss: 0.3914 - acc: 0.8535 - val_loss: 3.1538 - val_acc: 0.3750
Epoch 11/30
21/21 [==============================] - 0s 20ms/step - loss: 0.3670 - acc: 0.8520 - val_loss: 3.3635 - val_acc: 0.4405
Epoch 12/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3947 - acc: 0.8505 - val_loss: 3.6014 - val_acc: 0.4107
Epoch 13/30
21/21 [==============================] - 0s 18ms/step - loss: 0.3411 - acc: 0.8954 - val_loss: 3.6318 - val_acc: 0.3929
Epoch 14/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3825 - acc: 0.8849 - val_loss: 3.8205 - val_acc: 0.4048
Epoch 15/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3629 - acc: 0.8819 - val_loss: 3.9185 - val_acc: 0.3869
Epoch 16/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3545 - acc: 0.8909 - val_loss: 3.9691 - val_acc: 0.4226
Epoch 17/30
21/21 [==============================] - 0s 20ms/step - loss: 0.3588 - acc: 0.8879 - val_loss: 4.0537 - val_acc: 0.4107
Epoch 18/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2560 - acc: 0.9133 - val_loss: 4.3031 - val_acc: 0.4048
Epoch 19/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3347 - acc: 0.8894 - val_loss: 4.3170 - val_acc: 0.3929
Epoch 20/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2670 - acc: 0.9193 - val_loss: 4.5187 - val_acc: 0.3810
Epoch 21/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2797 - acc: 0.9058 - val_loss: 4.3831 - val_acc: 0.4107
Epoch 22/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2947 - acc: 0.9013 - val_loss: 4.7886 - val_acc: 0.3929
Epoch 23/30
21/21 [==============================] - 0s 19ms/step - loss: 0.3169 - acc: 0.9088 - val_loss: 4.8907 - val_acc: 0.3929
Epoch 24/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2970 - acc: 0.9028 - val_loss: 4.7136 - val_acc: 0.4167
Epoch 25/30
21/21 [==============================] - 0s 18ms/step - loss: 0.2746 - acc: 0.9163 - val_loss: 4.8910 - val_acc: 0.4167
Epoch 26/30
21/21 [==============================] - 0s 18ms/step - loss: 0.2868 - acc: 0.9088 - val_loss: 4.8159 - val_acc: 0.3929
Epoch 27/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2609 - acc: 0.9193 - val_loss: 4.8789 - val_acc: 0.3690
Epoch 28/30
21/21 [==============================] - 0s 18ms/step - loss: 0.2605 - acc: 0.9268 - val_loss: 5.0692 - val_acc: 0.3690
Epoch 29/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2633 - acc: 0.9178 - val_loss: 4.9734 - val_acc: 0.4167
Epoch 30/30
21/21 [==============================] - 0s 19ms/step - loss: 0.2817 - acc: 0.9103 - val_loss: 5.1644 - val_acc: 0.3929
{'loss': [1.3855904340744019, 1.1002875566482544, 0.8623965382575989, 0.6973595023155212, 0.5562048554420471, 0.4759288728237152, 0.5132670998573303, 0.5551157593727112, 0.37232211232185364, 0.3913919925689697, 0.36700159311294556, 0.3947390913963318, 0.3411308228969574, 0.38246607780456543, 0.36294829845428467, 0.3544546365737915, 0.35878920555114746, 0.2559962570667267, 0.33474141359329224, 0.26699212193489075, 0.2796787917613983, 0.2946580648422241, 0.31691837310791016, 0.29700133204460144, 0.2745542526245117, 0.28683018684387207, 0.26090213656425476, 0.2605212926864624, 0.2632770538330078, 0.2816820740699768], 'acc': [0.3437967002391815, 0.5097159743309021, 0.6606875658035278, 0.7159940004348755, 0.7832586169242859, 0.8116592168807983, 0.8131539821624756, 0.7832586169242859, 0.8669655919075012, 0.853512704372406, 0.8520179390907288, 0.8505231738090515, 0.8953661918640137, 0.884902834892273, 0.8819133043289185, 0.8908818960189819, 0.8878923654556274, 0.9133034348487854, 0.8893871307373047, 0.9192824959754944, 0.9058296084403992, 0.9013453125953674, 0.9088191390037537, 0.9028400778770447, 0.9162929654121399, 0.9088191390037537, 0.9192824959754944, 0.9267563819885254, 0.9177877306938171, 0.9103139042854309], 'val_loss': [1.3209521770477295, 1.2868382930755615, 1.6989864110946655, 1.8024569749832153, 2.0099575519561768, 2.3427042961120605, 2.9104981422424316, 2.7189812660217285, 2.9955029487609863, 3.153792142868042, 3.363499641418457, 3.6014084815979004, 3.6317880153656006, 3.820509672164917, 3.918487071990967, 3.9691479206085205, 4.053708553314209, 4.303055763244629, 4.317018508911133, 4.518733501434326, 4.38312292098999, 4.788578033447266, 4.890697002410889, 4.713593482971191, 4.891010284423828, 4.815948009490967, 4.878905296325684, 5.069170951843262, 4.973351955413818, 5.164351463317871], 'val_acc': [0.369047611951828, 0.4107142984867096, 0.4047619104385376, 0.4107142984867096, 0.4107142984867096, 0.4166666567325592, 0.4047619104385376, 0.3928571343421936, 0.363095223903656, 0.375, 0.4404761791229248, 0.4107142984867096, 0.3928571343421936, 0.4047619104385376, 0.386904776096344, 0.4226190447807312, 0.4107142984867096, 0.4047619104385376, 0.3928571343421936, 0.380952388048172, 0.4107142984867096, 0.3928571343421936, 0.3928571343421936, 0.4166666567325592, 0.4166666567325592, 0.3928571343421936, 0.369047611951828, 0.369047611951828, 0.4166666567325592, 0.3928571343421936]}
5/5 [==============================] - 0s 4ms/step - loss: 5.3404 - acc: 0.2600