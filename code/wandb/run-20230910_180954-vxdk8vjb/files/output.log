c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/20
21/21 [==============================] - 1s 25ms/step - loss: 1.4903 - acc: 0.2765 - val_loss: 1.4693 - val_acc: 0.3274
Epoch 2/20
21/21 [==============================] - 0s 19ms/step - loss: 1.1348 - acc: 0.5247 - val_loss: 1.6072 - val_acc: 0.3214
Epoch 3/20
21/21 [==============================] - 0s 19ms/step - loss: 0.8737 - acc: 0.6592 - val_loss: 1.6991 - val_acc: 0.3690
Epoch 4/20
21/21 [==============================] - 0s 19ms/step - loss: 0.7140 - acc: 0.7235 - val_loss: 1.9295 - val_acc: 0.3929
Epoch 5/20
21/21 [==============================] - 0s 19ms/step - loss: 0.6497 - acc: 0.7459 - val_loss: 2.3907 - val_acc: 0.3155
Epoch 6/20
21/21 [==============================] - 0s 19ms/step - loss: 0.6848 - acc: 0.7549 - val_loss: 2.4703 - val_acc: 0.3869
Epoch 7/20
21/21 [==============================] - 0s 19ms/step - loss: 0.6467 - acc: 0.7549 - val_loss: 2.7667 - val_acc: 0.4167
Epoch 8/20
21/21 [==============================] - 0s 19ms/step - loss: 0.5252 - acc: 0.8042 - val_loss: 2.8365 - val_acc: 0.3690
Epoch 9/20
21/21 [==============================] - 0s 20ms/step - loss: 0.4541 - acc: 0.8430 - val_loss: 3.2760 - val_acc: 0.3333
Epoch 10/20
21/21 [==============================] - 0s 19ms/step - loss: 0.4760 - acc: 0.8475 - val_loss: 3.6562 - val_acc: 0.3512
Epoch 11/20
21/21 [==============================] - 0s 19ms/step - loss: 0.5672 - acc: 0.8296 - val_loss: 4.0615 - val_acc: 0.3631
Epoch 12/20
21/21 [==============================] - 0s 19ms/step - loss: 0.5380 - acc: 0.8281 - val_loss: 4.0349 - val_acc: 0.3452
Epoch 13/20
21/21 [==============================] - 0s 19ms/step - loss: 0.4862 - acc: 0.8655 - val_loss: 3.8807 - val_acc: 0.3214
Epoch 14/20
21/21 [==============================] - 0s 21ms/step - loss: 0.3786 - acc: 0.8714 - val_loss: 3.9941 - val_acc: 0.3393
Epoch 15/20
21/21 [==============================] - 0s 19ms/step - loss: 0.3511 - acc: 0.8939 - val_loss: 4.2154 - val_acc: 0.3571
Epoch 16/20
21/21 [==============================] - 0s 19ms/step - loss: 0.4179 - acc: 0.8894 - val_loss: 4.8598 - val_acc: 0.3214
Epoch 17/20
21/21 [==============================] - 0s 20ms/step - loss: 0.4832 - acc: 0.8655 - val_loss: 4.6328 - val_acc: 0.3333
Epoch 18/20
21/21 [==============================] - 0s 19ms/step - loss: 0.4720 - acc: 0.8535 - val_loss: 5.8808 - val_acc: 0.3214
Epoch 19/20
21/21 [==============================] - 0s 19ms/step - loss: 0.5375 - acc: 0.8490 - val_loss: 5.1094 - val_acc: 0.3274
Epoch 20/20
21/21 [==============================] - 0s 19ms/step - loss: 0.4086 - acc: 0.8954 - val_loss: 5.8812 - val_acc: 0.3214
{'loss': [1.4902559518814087, 1.1347519159317017, 0.8737013936042786, 0.7140363454818726, 0.6497103571891785, 0.6847825050354004, 0.6467151045799255, 0.525183916091919, 0.454088419675827, 0.4760230481624603, 0.567210853099823, 0.5380224585533142, 0.4862426519393921, 0.37855979800224304, 0.3510799705982208, 0.4178941547870636, 0.48317432403564453, 0.4719831645488739, 0.5374975800514221, 0.4086112976074219], 'acc': [0.2765321433544159, 0.5246636867523193, 0.6591928005218506, 0.7234678864479065, 0.7458893656730652, 0.7548580169677734, 0.7548580169677734, 0.8041853308677673, 0.8430493474006653, 0.847533643245697, 0.8295964002609253, 0.828101634979248, 0.865470826625824, 0.8714499473571777, 0.8938714265823364, 0.8893871307373047, 0.865470826625824, 0.853512704372406, 0.8490284085273743, 0.8953661918640137], 'val_loss': [1.4692974090576172, 1.6072051525115967, 1.6991300582885742, 1.9294999837875366, 2.3906924724578857, 2.4703245162963867, 2.766667604446411, 2.8364546298980713, 3.276002883911133, 3.6562228202819824, 4.061504364013672, 4.034914493560791, 3.880711078643799, 3.99406361579895, 4.215446949005127, 4.859811305999756, 4.632819175720215, 5.880815505981445, 5.109415531158447, 5.88124942779541], 'val_acc': [0.3273809552192688, 0.3214285671710968, 0.369047611951828, 0.3928571343421936, 0.3154761791229248, 0.386904776096344, 0.4166666567325592, 0.369047611951828, 0.3333333432674408, 0.3511904776096344, 0.363095223903656, 0.3452380895614624, 0.3214285671710968, 0.3392857015132904, 0.3571428656578064, 0.3214285671710968, 0.3333333432674408, 0.3214285671710968, 0.3273809552192688, 0.3214285671710968]}
5/5 [==============================] - 0s 3ms/step - loss: 4.4246 - acc: 0.4333