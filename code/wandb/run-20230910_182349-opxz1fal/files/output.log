c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/20
21/21 [==============================] - 1s 25ms/step - loss: 1.7578 - acc: 0.3004 - val_loss: 1.3236 - val_acc: 0.3869
Epoch 2/20
21/21 [==============================] - 0s 19ms/step - loss: 1.2073 - acc: 0.5157 - val_loss: 1.8337 - val_acc: 0.3512
Epoch 3/20
21/21 [==============================] - 0s 19ms/step - loss: 1.0547 - acc: 0.6099 - val_loss: 1.9514 - val_acc: 0.4048
Epoch 4/20
21/21 [==============================] - 0s 19ms/step - loss: 0.8598 - acc: 0.7010 - val_loss: 2.5524 - val_acc: 0.3631
Epoch 5/20
21/21 [==============================] - 0s 19ms/step - loss: 1.1881 - acc: 0.6577 - val_loss: 2.7207 - val_acc: 0.4286
Epoch 6/20
21/21 [==============================] - 0s 19ms/step - loss: 1.1272 - acc: 0.6697 - val_loss: 3.5643 - val_acc: 0.3631
Epoch 7/20
21/21 [==============================] - 0s 19ms/step - loss: 1.0722 - acc: 0.7205 - val_loss: 3.7765 - val_acc: 0.3869
Epoch 8/20
21/21 [==============================] - 0s 19ms/step - loss: 0.8156 - acc: 0.7773 - val_loss: 3.7248 - val_acc: 0.3690
Epoch 9/20
21/21 [==============================] - 0s 21ms/step - loss: 0.9056 - acc: 0.7818 - val_loss: 4.6451 - val_acc: 0.3452
Epoch 10/20
21/21 [==============================] - 0s 19ms/step - loss: 1.2330 - acc: 0.7429 - val_loss: 4.8347 - val_acc: 0.4286
Epoch 11/20
21/21 [==============================] - 0s 20ms/step - loss: 0.9185 - acc: 0.7862 - val_loss: 5.4995 - val_acc: 0.4107
Epoch 12/20
21/21 [==============================] - 0s 19ms/step - loss: 0.8596 - acc: 0.8102 - val_loss: 6.0062 - val_acc: 0.3512
Epoch 13/20
21/21 [==============================] - 0s 19ms/step - loss: 0.8135 - acc: 0.8281 - val_loss: 6.4397 - val_acc: 0.3512
Epoch 14/20
21/21 [==============================] - 0s 19ms/step - loss: 1.0682 - acc: 0.7967 - val_loss: 6.6665 - val_acc: 0.4107
Epoch 15/20
21/21 [==============================] - 0s 19ms/step - loss: 1.1953 - acc: 0.7698 - val_loss: 7.1934 - val_acc: 0.3750
Epoch 16/20
21/21 [==============================] - 0s 19ms/step - loss: 1.3486 - acc: 0.7862 - val_loss: 7.6502 - val_acc: 0.3750
Epoch 17/20
21/21 [==============================] - 0s 19ms/step - loss: 1.3454 - acc: 0.7922 - val_loss: 8.5901 - val_acc: 0.3750
Epoch 18/20
21/21 [==============================] - 0s 19ms/step - loss: 1.4250 - acc: 0.7818 - val_loss: 9.0193 - val_acc: 0.3929
Epoch 19/20
21/21 [==============================] - 0s 19ms/step - loss: 1.2766 - acc: 0.8146 - val_loss: 10.0616 - val_acc: 0.3690
Epoch 20/20
21/21 [==============================] - 0s 20ms/step - loss: 1.1717 - acc: 0.8416 - val_loss: 10.2413 - val_acc: 0.3571
{'loss': [1.7578128576278687, 1.2073218822479248, 1.0546808242797852, 0.8597639203071594, 1.1880946159362793, 1.1271679401397705, 1.0721769332885742, 0.8156325221061707, 0.9056445956230164, 1.232966661453247, 0.9184900522232056, 0.8595578074455261, 0.8134521245956421, 1.0681904554367065, 1.195319652557373, 1.3485537767410278, 1.3454186916351318, 1.4250071048736572, 1.2766462564468384, 1.171725869178772], 'acc': [0.3004484176635742, 0.5156950950622559, 0.6098654866218567, 0.701046347618103, 0.6576980352401733, 0.6696562170982361, 0.7204782962799072, 0.7772794961929321, 0.7817638516426086, 0.7428998351097107, 0.7862481474876404, 0.8101644515991211, 0.828101634979248, 0.7967115044593811, 0.7698056697845459, 0.7862481474876404, 0.7922272086143494, 0.7817638516426086, 0.8146487474441528, 0.841554582118988], 'val_loss': [1.3236429691314697, 1.8337103128433228, 1.9514318704605103, 2.5524139404296875, 2.72066068649292, 3.5643186569213867, 3.77649188041687, 3.724775791168213, 4.645052909851074, 4.834726333618164, 5.499471664428711, 6.00622034072876, 6.439697265625, 6.6665263175964355, 7.193384647369385, 7.650235176086426, 8.590133666992188, 9.019339561462402, 10.061567306518555, 10.241348266601562], 'val_acc': [0.386904776096344, 0.3511904776096344, 0.4047619104385376, 0.363095223903656, 0.4285714328289032, 0.363095223903656, 0.386904776096344, 0.369047611951828, 0.3452380895614624, 0.4285714328289032, 0.4107142984867096, 0.3511904776096344, 0.3511904776096344, 0.4107142984867096, 0.375, 0.375, 0.375, 0.3928571343421936, 0.369047611951828, 0.3571428656578064]}
5/5 [==============================] - 0s 4ms/step - loss: 14.5047 - acc: 0.2733