c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/30
21/21 [==============================] - 1s 14ms/step - loss: 1.3828 - acc: 0.2556 - val_loss: 1.3662 - val_acc: 0.3333
Epoch 2/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3765 - acc: 0.2855 - val_loss: 1.3566 - val_acc: 0.2917
Epoch 3/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3738 - acc: 0.2900 - val_loss: 1.3507 - val_acc: 0.2917
Epoch 4/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3724 - acc: 0.2676 - val_loss: 1.3469 - val_acc: 0.2917
Epoch 5/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3719 - acc: 0.2825 - val_loss: 1.3452 - val_acc: 0.2917
Epoch 6/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3713 - acc: 0.2810 - val_loss: 1.3440 - val_acc: 0.2917
Epoch 7/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3718 - acc: 0.2840 - val_loss: 1.3429 - val_acc: 0.2917
Epoch 8/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3698 - acc: 0.2945 - val_loss: 1.3425 - val_acc: 0.2917
Epoch 9/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3708 - acc: 0.2780 - val_loss: 1.3419 - val_acc: 0.2857
Epoch 10/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3700 - acc: 0.2930 - val_loss: 1.3414 - val_acc: 0.2917
Epoch 11/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3675 - acc: 0.3019 - val_loss: 1.3414 - val_acc: 0.2976
Epoch 12/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3697 - acc: 0.2750 - val_loss: 1.3417 - val_acc: 0.2976
Epoch 13/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3701 - acc: 0.2900 - val_loss: 1.3410 - val_acc: 0.2976
Epoch 14/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3689 - acc: 0.2720 - val_loss: 1.3406 - val_acc: 0.3393
Epoch 15/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3676 - acc: 0.2825 - val_loss: 1.3401 - val_acc: 0.3333
Epoch 16/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3683 - acc: 0.2855 - val_loss: 1.3398 - val_acc: 0.3095
Epoch 17/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3684 - acc: 0.2885 - val_loss: 1.3396 - val_acc: 0.3452
Epoch 18/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3690 - acc: 0.2825 - val_loss: 1.3397 - val_acc: 0.3393
Epoch 19/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3675 - acc: 0.2900 - val_loss: 1.3395 - val_acc: 0.3452
Epoch 20/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3672 - acc: 0.2990 - val_loss: 1.3394 - val_acc: 0.3333
Epoch 21/30
21/21 [==============================] - 0s 10ms/step - loss: 1.3656 - acc: 0.3049 - val_loss: 1.3390 - val_acc: 0.3452
Epoch 22/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3676 - acc: 0.2765 - val_loss: 1.3389 - val_acc: 0.3393
Epoch 23/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3665 - acc: 0.2825 - val_loss: 1.3381 - val_acc: 0.3452
Epoch 24/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3664 - acc: 0.2975 - val_loss: 1.3384 - val_acc: 0.3155
Epoch 25/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3663 - acc: 0.2840 - val_loss: 1.3386 - val_acc: 0.3155
Epoch 26/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3670 - acc: 0.2750 - val_loss: 1.3376 - val_acc: 0.3452
Epoch 27/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3672 - acc: 0.2780 - val_loss: 1.3380 - val_acc: 0.3512
Epoch 28/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3660 - acc: 0.2975 - val_loss: 1.3378 - val_acc: 0.3393
Epoch 29/30
21/21 [==============================] - 0s 9ms/step - loss: 1.3642 - acc: 0.2915 - val_loss: 1.3383 - val_acc: 0.3214
Epoch 30/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3670 - acc: 0.2975 - val_loss: 1.3380 - val_acc: 0.3452
{'loss': [1.382807970046997, 1.376538634300232, 1.3738027811050415, 1.3723978996276855, 1.3719202280044556, 1.3712555170059204, 1.3718206882476807, 1.3698400259017944, 1.3707811832427979, 1.3700497150421143, 1.3675329685211182, 1.3697049617767334, 1.370110273361206, 1.3689026832580566, 1.3676432371139526, 1.3683067560195923, 1.3683931827545166, 1.369033694267273, 1.3674838542938232, 1.3671972751617432, 1.365566611289978, 1.3676074743270874, 1.366487979888916, 1.3664337396621704, 1.3663092851638794, 1.3669580221176147, 1.3672477006912231, 1.3660056591033936, 1.3641823530197144, 1.3670399188995361], 'acc': [0.2556053698062897, 0.28550073504447937, 0.2899850606918335, 0.26756352186203003, 0.2825112044811249, 0.28101643919944763, 0.2840059697628021, 0.29446935653686523, 0.27802690863609314, 0.292974591255188, 0.30194321274757385, 0.27503737807273865, 0.2899850606918335, 0.27204781770706177, 0.2825112044811249, 0.28550073504447937, 0.28849029541015625, 0.2825112044811249, 0.2899850606918335, 0.298953652381897, 0.30493274331092834, 0.2765321433544159, 0.2825112044811249, 0.2974588871002197, 0.2840059697628021, 0.27503737807273865, 0.27802690863609314, 0.2974588871002197, 0.29147982597351074, 0.2974588871002197], 'val_loss': [1.3661891222000122, 1.356612205505371, 1.350700855255127, 1.3469020128250122, 1.3452448844909668, 1.3440191745758057, 1.3428850173950195, 1.342517375946045, 1.3418768644332886, 1.341444969177246, 1.3413645029067993, 1.3416907787322998, 1.3410316705703735, 1.3405606746673584, 1.3400959968566895, 1.339762568473816, 1.3396198749542236, 1.3396942615509033, 1.3395299911499023, 1.3394434452056885, 1.3389761447906494, 1.3388742208480835, 1.3380693197250366, 1.338427186012268, 1.3385884761810303, 1.3376163244247437, 1.3379509449005127, 1.3378130197525024, 1.3382655382156372, 1.3379873037338257], 'val_acc': [0.3333333432674408, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2916666567325592, 0.2857142984867096, 0.2916666567325592, 0.2976190447807312, 0.2976190447807312, 0.2976190447807312, 0.3392857015132904, 0.3333333432674408, 0.3095238208770752, 0.3452380895614624, 0.3392857015132904, 0.3452380895614624, 0.3333333432674408, 0.3452380895614624, 0.3392857015132904, 0.3452380895614624, 0.3154761791229248, 0.3154761791229248, 0.3452380895614624, 0.3511904776096344, 0.3392857015132904, 0.3214285671710968, 0.3452380895614624]}
5/5 [==============================] - 0s 3ms/step - loss: 1.5699 - acc: 0.1133