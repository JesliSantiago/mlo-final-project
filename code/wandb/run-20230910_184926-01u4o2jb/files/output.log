c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/30
21/21 [==============================] - 1s 12ms/step - loss: 1.3806 - acc: 0.2720 - val_loss: 1.3722 - val_acc: 0.3214
Epoch 2/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3726 - acc: 0.2825 - val_loss: 1.3661 - val_acc: 0.3155
Epoch 3/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3698 - acc: 0.2885 - val_loss: 1.3633 - val_acc: 0.3155
Epoch 4/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3681 - acc: 0.2825 - val_loss: 1.3626 - val_acc: 0.3036
Epoch 5/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3674 - acc: 0.2765 - val_loss: 1.3616 - val_acc: 0.3036
Epoch 6/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3670 - acc: 0.2735 - val_loss: 1.3613 - val_acc: 0.2560
Epoch 7/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3666 - acc: 0.2810 - val_loss: 1.3606 - val_acc: 0.3095
Epoch 8/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3666 - acc: 0.2631 - val_loss: 1.3606 - val_acc: 0.2976
Epoch 9/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3646 - acc: 0.3019 - val_loss: 1.3609 - val_acc: 0.3036
Epoch 10/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3647 - acc: 0.3124 - val_loss: 1.3608 - val_acc: 0.2798
Epoch 11/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3644 - acc: 0.3214 - val_loss: 1.3606 - val_acc: 0.2857
Epoch 12/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3639 - acc: 0.2945 - val_loss: 1.3604 - val_acc: 0.3036
Epoch 13/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3646 - acc: 0.3079 - val_loss: 1.3602 - val_acc: 0.2976
Epoch 14/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3648 - acc: 0.3049 - val_loss: 1.3602 - val_acc: 0.3095
Epoch 15/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3629 - acc: 0.3079 - val_loss: 1.3598 - val_acc: 0.3155
Epoch 16/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3635 - acc: 0.3019 - val_loss: 1.3595 - val_acc: 0.2976
Epoch 17/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3628 - acc: 0.2885 - val_loss: 1.3601 - val_acc: 0.2917
Epoch 18/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3612 - acc: 0.3019 - val_loss: 1.3600 - val_acc: 0.3214
Epoch 19/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3629 - acc: 0.3019 - val_loss: 1.3602 - val_acc: 0.3036
Epoch 20/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3619 - acc: 0.2855 - val_loss: 1.3600 - val_acc: 0.3095
Epoch 21/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3626 - acc: 0.2810 - val_loss: 1.3607 - val_acc: 0.2917
Epoch 22/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3616 - acc: 0.3034 - val_loss: 1.3608 - val_acc: 0.2857
Epoch 23/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3611 - acc: 0.2945 - val_loss: 1.3606 - val_acc: 0.2976
Epoch 24/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3613 - acc: 0.3049 - val_loss: 1.3604 - val_acc: 0.3036
Epoch 25/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3608 - acc: 0.2945 - val_loss: 1.3605 - val_acc: 0.2976
Epoch 26/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3608 - acc: 0.3019 - val_loss: 1.3602 - val_acc: 0.3095
Epoch 27/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3609 - acc: 0.3004 - val_loss: 1.3603 - val_acc: 0.2976
Epoch 28/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3581 - acc: 0.3318 - val_loss: 1.3606 - val_acc: 0.2976
Epoch 29/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3595 - acc: 0.3184 - val_loss: 1.3601 - val_acc: 0.3214
Epoch 30/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3610 - acc: 0.2945 - val_loss: 1.3602 - val_acc: 0.3095
{'loss': [1.3806072473526, 1.3725793361663818, 1.3697501420974731, 1.3681180477142334, 1.3673616647720337, 1.367000937461853, 1.3665555715560913, 1.3666454553604126, 1.364594578742981, 1.3647093772888184, 1.3643940687179565, 1.363925814628601, 1.3645553588867188, 1.3647733926773071, 1.3628594875335693, 1.3634876012802124, 1.362831950187683, 1.3611506223678589, 1.3629497289657593, 1.3619410991668701, 1.3626422882080078, 1.3616015911102295, 1.361124038696289, 1.3612526655197144, 1.360807180404663, 1.3607882261276245, 1.3608750104904175, 1.358074426651001, 1.3594741821289062, 1.361010193824768], 'acc': [0.27204781770706177, 0.2825112044811249, 0.28849029541015625, 0.2825112044811249, 0.2765321433544159, 0.2735426127910614, 0.28101643919944763, 0.2630792260169983, 0.30194321274757385, 0.3124065697193146, 0.32137519121170044, 0.29446935653686523, 0.30792227387428284, 0.30493274331092834, 0.30792227387428284, 0.30194321274757385, 0.28849029541015625, 0.30194321274757385, 0.30194321274757385, 0.28550073504447937, 0.28101643919944763, 0.3034379780292511, 0.29446935653686523, 0.30493274331092834, 0.29446935653686523, 0.30194321274757385, 0.3004484176635742, 0.33183857798576355, 0.31838566064834595, 0.29446935653686523], 'val_loss': [1.372206211090088, 1.3661267757415771, 1.3633239269256592, 1.362554907798767, 1.3615601062774658, 1.361313819885254, 1.3606085777282715, 1.3605748414993286, 1.3608719110488892, 1.3608355522155762, 1.360609531402588, 1.3604100942611694, 1.3602277040481567, 1.360213279724121, 1.3598463535308838, 1.3595088720321655, 1.3601161241531372, 1.3599883317947388, 1.360234260559082, 1.360047459602356, 1.3606714010238647, 1.3608181476593018, 1.3605958223342896, 1.3604000806808472, 1.3604519367218018, 1.3601552248001099, 1.3603025674819946, 1.36063551902771, 1.3601168394088745, 1.3601670265197754], 'val_acc': [0.3214285671710968, 0.3154761791229248, 0.3154761791229248, 0.3035714328289032, 0.3035714328289032, 0.255952388048172, 0.3095238208770752, 0.2976190447807312, 0.3035714328289032, 0.2797619104385376, 0.2857142984867096, 0.3035714328289032, 0.2976190447807312, 0.3095238208770752, 0.3154761791229248, 0.2976190447807312, 0.2916666567325592, 0.3214285671710968, 0.3035714328289032, 0.3095238208770752, 0.2916666567325592, 0.2857142984867096, 0.2976190447807312, 0.3035714328289032, 0.2976190447807312, 0.3095238208770752, 0.2976190447807312, 0.2976190447807312, 0.3214285671710968, 0.3095238208770752]}
5/5 [==============================] - 0s 2ms/step - loss: 1.6089 - acc: 0.1400