c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/30
21/21 [==============================] - 1s 14ms/step - loss: 1.3810 - acc: 0.2735 - val_loss: 1.3765 - val_acc: 0.2857
Epoch 2/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3702 - acc: 0.3079 - val_loss: 1.3739 - val_acc: 0.2976
Epoch 3/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3659 - acc: 0.2765 - val_loss: 1.3733 - val_acc: 0.2917
Epoch 4/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3633 - acc: 0.2780 - val_loss: 1.3735 - val_acc: 0.2917
Epoch 5/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3630 - acc: 0.2855 - val_loss: 1.3743 - val_acc: 0.2857
Epoch 6/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3607 - acc: 0.3064 - val_loss: 1.3748 - val_acc: 0.2917
Epoch 7/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3620 - acc: 0.3049 - val_loss: 1.3755 - val_acc: 0.2857
Epoch 8/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3611 - acc: 0.2960 - val_loss: 1.3759 - val_acc: 0.2738
Epoch 9/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3588 - acc: 0.3004 - val_loss: 1.3763 - val_acc: 0.2619
Epoch 10/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3580 - acc: 0.3034 - val_loss: 1.3766 - val_acc: 0.2798
Epoch 11/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3586 - acc: 0.2960 - val_loss: 1.3770 - val_acc: 0.2619
Epoch 12/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3574 - acc: 0.3064 - val_loss: 1.3776 - val_acc: 0.2679
Epoch 13/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3571 - acc: 0.3004 - val_loss: 1.3782 - val_acc: 0.2857
Epoch 14/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3582 - acc: 0.3109 - val_loss: 1.3788 - val_acc: 0.2976
Epoch 15/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3593 - acc: 0.3094 - val_loss: 1.3788 - val_acc: 0.2917
Epoch 16/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3569 - acc: 0.3019 - val_loss: 1.3792 - val_acc: 0.2857
Epoch 17/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3579 - acc: 0.3034 - val_loss: 1.3792 - val_acc: 0.2500
Epoch 18/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3567 - acc: 0.3034 - val_loss: 1.3796 - val_acc: 0.2619
Epoch 19/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3554 - acc: 0.3064 - val_loss: 1.3798 - val_acc: 0.2560
Epoch 20/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3551 - acc: 0.3094 - val_loss: 1.3802 - val_acc: 0.2798
Epoch 21/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3535 - acc: 0.3184 - val_loss: 1.3806 - val_acc: 0.2500
Epoch 22/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3562 - acc: 0.2990 - val_loss: 1.3807 - val_acc: 0.2381
Epoch 23/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3565 - acc: 0.3079 - val_loss: 1.3812 - val_acc: 0.2381
Epoch 24/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3554 - acc: 0.2990 - val_loss: 1.3812 - val_acc: 0.2381
Epoch 25/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3545 - acc: 0.3079 - val_loss: 1.3815 - val_acc: 0.2321
Epoch 26/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3568 - acc: 0.2915 - val_loss: 1.3816 - val_acc: 0.2321
Epoch 27/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3550 - acc: 0.2930 - val_loss: 1.3818 - val_acc: 0.2381
Epoch 28/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3535 - acc: 0.3244 - val_loss: 1.3824 - val_acc: 0.2500
Epoch 29/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3529 - acc: 0.3244 - val_loss: 1.3829 - val_acc: 0.2560
Epoch 30/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3554 - acc: 0.3034 - val_loss: 1.3832 - val_acc: 0.2560
{'loss': [1.3809844255447388, 1.3701967000961304, 1.3658547401428223, 1.363294005393982, 1.363016963005066, 1.3606994152069092, 1.3619835376739502, 1.3611191511154175, 1.3588159084320068, 1.3580496311187744, 1.3585960865020752, 1.3573623895645142, 1.3570698499679565, 1.3581831455230713, 1.3593300580978394, 1.3569493293762207, 1.3579075336456299, 1.356740951538086, 1.355385661125183, 1.3550610542297363, 1.353515386581421, 1.3562499284744263, 1.3564742803573608, 1.3553552627563477, 1.3545364141464233, 1.3568280935287476, 1.3550363779067993, 1.3534656763076782, 1.3528666496276855, 1.3554277420043945], 'acc': [0.2735426127910614, 0.30792227387428284, 0.2765321433544159, 0.27802690863609314, 0.28550073504447937, 0.3064275085926056, 0.30493274331092834, 0.2959641218185425, 0.3004484176635742, 0.3034379780292511, 0.2959641218185425, 0.3064275085926056, 0.3004484176635742, 0.31091180443763733, 0.3094170391559601, 0.30194321274757385, 0.3034379780292511, 0.3034379780292511, 0.3064275085926056, 0.3094170391559601, 0.31838566064834595, 0.298953652381897, 0.30792227387428284, 0.298953652381897, 0.30792227387428284, 0.29147982597351074, 0.292974591255188, 0.32436472177505493, 0.32436472177505493, 0.3034379780292511], 'val_loss': [1.3765356540679932, 1.3739248514175415, 1.3732755184173584, 1.3735027313232422, 1.3743184804916382, 1.3748183250427246, 1.3755133152008057, 1.375902771949768, 1.376263976097107, 1.3766365051269531, 1.376989722251892, 1.377593994140625, 1.3782072067260742, 1.3788007497787476, 1.3788340091705322, 1.3792059421539307, 1.3792269229888916, 1.379622220993042, 1.3798284530639648, 1.3801648616790771, 1.3806490898132324, 1.380704402923584, 1.3811626434326172, 1.381186842918396, 1.3814557790756226, 1.3815765380859375, 1.381764531135559, 1.3824094533920288, 1.3828835487365723, 1.383224606513977], 'val_acc': [0.2857142984867096, 0.2976190447807312, 0.2916666567325592, 0.2916666567325592, 0.2857142984867096, 0.2916666567325592, 0.2857142984867096, 0.2738095223903656, 0.261904776096344, 0.2797619104385376, 0.261904776096344, 0.2678571343421936, 0.2857142984867096, 0.2976190447807312, 0.2916666567325592, 0.2857142984867096, 0.25, 0.261904776096344, 0.255952388048172, 0.2797619104385376, 0.25, 0.2380952388048172, 0.2380952388048172, 0.2380952388048172, 0.2321428507566452, 0.2321428507566452, 0.2380952388048172, 0.25, 0.255952388048172, 0.255952388048172]}
5/5 [==============================] - 0s 3ms/step - loss: 1.6236 - acc: 0.1467