c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:47: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('shade.When', 'shade. When')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:48: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now', 'afraid. Now')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:50: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('afraid.Now,', 'afraid. Now,')
c:\Users\Jesli's Laptop\Desktop\Acads\MLO\mlo-final-project\code\model.py:51: FutureWarning: The default value of regex will change from True to False in a future version.
  self.df_train['Poem'] = self.df_train['Poem'].str.replace('Big Game.Bigger', 'Big Game. Bigger')
[nltk_data] Downloading package stopwords to C:\Users\Jesli's
[nltk_data]     Laptop\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Epoch 1/30
21/21 [==============================] - 1s 12ms/step - loss: 1.3764 - acc: 0.2541 - val_loss: 1.3829 - val_acc: 0.2500
Epoch 2/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3657 - acc: 0.2735 - val_loss: 1.3851 - val_acc: 0.2500
Epoch 3/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3613 - acc: 0.2900 - val_loss: 1.3867 - val_acc: 0.2381
Epoch 4/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3588 - acc: 0.2930 - val_loss: 1.3886 - val_acc: 0.2500
Epoch 5/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3583 - acc: 0.3049 - val_loss: 1.3898 - val_acc: 0.2500
Epoch 6/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3576 - acc: 0.3019 - val_loss: 1.3903 - val_acc: 0.2440
Epoch 7/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3570 - acc: 0.2945 - val_loss: 1.3905 - val_acc: 0.2440
Epoch 8/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3571 - acc: 0.3019 - val_loss: 1.3914 - val_acc: 0.2440
Epoch 9/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3569 - acc: 0.2915 - val_loss: 1.3915 - val_acc: 0.2321
Epoch 10/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3556 - acc: 0.2960 - val_loss: 1.3909 - val_acc: 0.2381
Epoch 11/30
21/21 [==============================] - 0s 6ms/step - loss: 1.3552 - acc: 0.3154 - val_loss: 1.3916 - val_acc: 0.2381
Epoch 12/30
21/21 [==============================] - 0s 21ms/step - loss: 1.3561 - acc: 0.2945 - val_loss: 1.3914 - val_acc: 0.2500
Epoch 13/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3551 - acc: 0.3214 - val_loss: 1.3915 - val_acc: 0.2440
Epoch 14/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3559 - acc: 0.3109 - val_loss: 1.3919 - val_acc: 0.2440
Epoch 15/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3546 - acc: 0.3109 - val_loss: 1.3920 - val_acc: 0.2440
Epoch 16/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3542 - acc: 0.2885 - val_loss: 1.3918 - val_acc: 0.2440
Epoch 17/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3528 - acc: 0.2990 - val_loss: 1.3922 - val_acc: 0.2500
Epoch 18/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3527 - acc: 0.3079 - val_loss: 1.3913 - val_acc: 0.2440
Epoch 19/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3528 - acc: 0.2855 - val_loss: 1.3916 - val_acc: 0.2321
Epoch 20/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3533 - acc: 0.3229 - val_loss: 1.3913 - val_acc: 0.2083
Epoch 21/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3518 - acc: 0.3214 - val_loss: 1.3905 - val_acc: 0.2202
Epoch 22/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3525 - acc: 0.2885 - val_loss: 1.3906 - val_acc: 0.2381
Epoch 23/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3521 - acc: 0.3214 - val_loss: 1.3901 - val_acc: 0.2262
Epoch 24/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3513 - acc: 0.2945 - val_loss: 1.3915 - val_acc: 0.2262
Epoch 25/30
21/21 [==============================] - 0s 8ms/step - loss: 1.3516 - acc: 0.3229 - val_loss: 1.3921 - val_acc: 0.2321
Epoch 26/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3520 - acc: 0.3079 - val_loss: 1.3921 - val_acc: 0.2381
Epoch 27/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3507 - acc: 0.3109 - val_loss: 1.3907 - val_acc: 0.2262
Epoch 28/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3521 - acc: 0.3139 - val_loss: 1.3901 - val_acc: 0.2619
Epoch 29/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3537 - acc: 0.3244 - val_loss: 1.3899 - val_acc: 0.2381
Epoch 30/30
21/21 [==============================] - 0s 7ms/step - loss: 1.3476 - acc: 0.3408 - val_loss: 1.3903 - val_acc: 0.2143
{'loss': [1.376360535621643, 1.365708351135254, 1.361319899559021, 1.3588029146194458, 1.3583334684371948, 1.3576499223709106, 1.3570399284362793, 1.3570631742477417, 1.3569228649139404, 1.3556039333343506, 1.355185627937317, 1.3560833930969238, 1.355102300643921, 1.3558807373046875, 1.3546128273010254, 1.3542042970657349, 1.3527575731277466, 1.3527251482009888, 1.3527555465698242, 1.3532642126083374, 1.351833701133728, 1.3524566888809204, 1.352107286453247, 1.3513004779815674, 1.351626992225647, 1.3519877195358276, 1.35074782371521, 1.3521379232406616, 1.353654384613037, 1.3476444482803345], 'acc': [0.2541106045246124, 0.2735426127910614, 0.2899850606918335, 0.292974591255188, 0.30493274331092834, 0.30194321274757385, 0.29446935653686523, 0.30194321274757385, 0.29147982597351074, 0.2959641218185425, 0.31539610028266907, 0.29446935653686523, 0.32137519121170044, 0.31091180443763733, 0.31091180443763733, 0.28849029541015625, 0.298953652381897, 0.30792227387428284, 0.28550073504447937, 0.3228699564933777, 0.32137519121170044, 0.28849029541015625, 0.32137519121170044, 0.29446935653686523, 0.3228699564933777, 0.30792227387428284, 0.31091180443763733, 0.3139013350009918, 0.32436472177505493, 0.340807169675827], 'val_loss': [1.3829104900360107, 1.3850853443145752, 1.3866527080535889, 1.388574481010437, 1.3898184299468994, 1.3903162479400635, 1.3904753923416138, 1.391399621963501, 1.391531229019165, 1.3909387588500977, 1.3916200399398804, 1.3914076089859009, 1.3914517164230347, 1.391898512840271, 1.3920015096664429, 1.391791820526123, 1.3922334909439087, 1.3912627696990967, 1.3915678262710571, 1.3912595510482788, 1.3904949426651, 1.390630841255188, 1.3900830745697021, 1.3915213346481323, 1.3920924663543701, 1.3921096324920654, 1.3907228708267212, 1.3901331424713135, 1.3899084329605103, 1.3903173208236694], 'val_acc': [0.25, 0.25, 0.2380952388048172, 0.25, 0.25, 0.244047611951828, 0.244047611951828, 0.244047611951828, 0.2321428507566452, 0.2380952388048172, 0.2380952388048172, 0.25, 0.244047611951828, 0.244047611951828, 0.244047611951828, 0.244047611951828, 0.25, 0.244047611951828, 0.2321428507566452, 0.2083333283662796, 0.2202380895614624, 0.2380952388048172, 0.2261904776096344, 0.2261904776096344, 0.2321428507566452, 0.2380952388048172, 0.2261904776096344, 0.261904776096344, 0.2380952388048172, 0.2142857164144516]}
5/5 [==============================] - 0s 3ms/step - loss: 1.6490 - acc: 0.1400